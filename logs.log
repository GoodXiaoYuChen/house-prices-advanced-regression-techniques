2023-04-19 15:52:06,891:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-19 15:52:06,891:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-19 15:52:06,891:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-19 15:52:06,891:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-19 15:52:20,246:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-19 16:05:16,438:WARNING:E:\python\Anaconda3\lib\site-packages\seaborn\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).
  warnings.warn(msg, FutureWarning)

2023-04-19 16:05:16,555:WARNING:E:\python\Anaconda3\lib\site-packages\seaborn\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).
  warnings.warn(msg, FutureWarning)

2023-04-19 16:35:24,539:INFO:PyCaret RegressionExperiment
2023-04-19 16:35:24,540:INFO:Logging name: reg-default-name
2023-04-19 16:35:24,540:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-19 16:35:24,540:INFO:version 3.0.0
2023-04-19 16:35:24,540:INFO:Initializing setup()
2023-04-19 16:35:24,540:INFO:self.USI: d527
2023-04-19 16:35:24,540:INFO:self._variable_keys: {'y_train', 'X_train', 'pipeline', '_available_plots', 'data', 'seed', 'transform_target_param', 'X_test', 'target_param', 'logging_param', 'fold_generator', 'fold_shuffle_param', '_ml_usecase', 'X', 'USI', 'gpu_param', 'html_param', 'log_plots_param', 'idx', 'exp_id', 'y', 'exp_name_log', 'n_jobs_param', 'memory', 'gpu_n_jobs_param', 'y_test', 'fold_groups_param'}
2023-04-19 16:35:24,540:INFO:Checking environment
2023-04-19 16:35:24,540:INFO:python_version: 3.9.13
2023-04-19 16:35:24,540:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-19 16:35:24,540:INFO:machine: AMD64
2023-04-19 16:35:24,541:INFO:platform: Windows-10-10.0.18363-SP0
2023-04-19 16:35:24,541:INFO:Memory: svmem(total=8488050688, available=2937905152, percent=65.4, used=5550145536, free=2937905152)
2023-04-19 16:35:24,541:INFO:Physical Core: 2
2023-04-19 16:35:24,541:INFO:Logical Core: 4
2023-04-19 16:35:24,541:INFO:Checking libraries
2023-04-19 16:35:24,541:INFO:System:
2023-04-19 16:35:24,541:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-19 16:35:24,541:INFO:executable: E:\python\Anaconda3\python.exe
2023-04-19 16:35:24,541:INFO:   machine: Windows-10-10.0.18363-SP0
2023-04-19 16:35:24,542:INFO:PyCaret required dependencies:
2023-04-19 16:35:24,542:INFO:                 pip: 22.2.2
2023-04-19 16:35:24,542:INFO:          setuptools: 63.4.1
2023-04-19 16:35:24,542:INFO:             pycaret: 3.0.0
2023-04-19 16:35:24,542:INFO:             IPython: 7.31.1
2023-04-19 16:35:24,542:INFO:          ipywidgets: 7.6.5
2023-04-19 16:35:24,542:INFO:                tqdm: 4.64.1
2023-04-19 16:35:24,542:INFO:               numpy: 1.21.5
2023-04-19 16:35:24,542:INFO:              pandas: 1.4.4
2023-04-19 16:35:24,543:INFO:              jinja2: 2.11.3
2023-04-19 16:35:24,543:INFO:               scipy: 1.9.1
2023-04-19 16:35:24,543:INFO:              joblib: 1.2.0
2023-04-19 16:35:24,543:INFO:             sklearn: 1.0.2
2023-04-19 16:35:24,543:INFO:                pyod: 1.0.9
2023-04-19 16:35:24,543:INFO:            imblearn: 0.10.1
2023-04-19 16:35:24,543:INFO:   category_encoders: 2.6.0
2023-04-19 16:35:24,543:INFO:            lightgbm: 3.3.5
2023-04-19 16:35:24,544:INFO:               numba: 0.55.1
2023-04-19 16:35:24,544:INFO:            requests: 2.28.1
2023-04-19 16:35:24,544:INFO:          matplotlib: 3.5.2
2023-04-19 16:35:24,544:INFO:          scikitplot: 0.3.7
2023-04-19 16:35:24,544:INFO:         yellowbrick: 1.5
2023-04-19 16:35:24,544:INFO:              plotly: 5.9.0
2023-04-19 16:35:24,544:INFO:             kaleido: 0.2.1
2023-04-19 16:35:24,544:INFO:         statsmodels: 0.13.2
2023-04-19 16:35:24,544:INFO:              sktime: 0.17.1
2023-04-19 16:35:24,544:INFO:               tbats: 1.1.3
2023-04-19 16:35:24,544:INFO:            pmdarima: 2.0.3
2023-04-19 16:35:24,544:INFO:              psutil: 5.9.0
2023-04-19 16:35:24,544:INFO:PyCaret optional dependencies:
2023-04-19 16:35:24,587:INFO:                shap: Not installed
2023-04-19 16:35:24,587:INFO:           interpret: Not installed
2023-04-19 16:35:24,587:INFO:                umap: Not installed
2023-04-19 16:35:24,587:INFO:    pandas_profiling: Not installed
2023-04-19 16:35:24,587:INFO:  explainerdashboard: Not installed
2023-04-19 16:35:24,587:INFO:             autoviz: Not installed
2023-04-19 16:35:24,588:INFO:           fairlearn: Not installed
2023-04-19 16:35:24,588:INFO:             xgboost: Not installed
2023-04-19 16:35:24,588:INFO:            catboost: Not installed
2023-04-19 16:35:24,588:INFO:              kmodes: Not installed
2023-04-19 16:35:24,588:INFO:             mlxtend: Not installed
2023-04-19 16:35:24,588:INFO:       statsforecast: Not installed
2023-04-19 16:35:24,588:INFO:        tune_sklearn: Not installed
2023-04-19 16:35:24,588:INFO:                 ray: Not installed
2023-04-19 16:35:24,588:INFO:            hyperopt: Not installed
2023-04-19 16:35:24,589:INFO:              optuna: Not installed
2023-04-19 16:35:24,589:INFO:               skopt: Not installed
2023-04-19 16:35:24,589:INFO:              mlflow: Not installed
2023-04-19 16:35:24,589:INFO:              gradio: Not installed
2023-04-19 16:35:24,589:INFO:             fastapi: Not installed
2023-04-19 16:35:24,589:INFO:             uvicorn: Not installed
2023-04-19 16:35:24,589:INFO:              m2cgen: Not installed
2023-04-19 16:35:24,590:INFO:           evidently: Not installed
2023-04-19 16:35:24,590:INFO:               fugue: Not installed
2023-04-19 16:35:24,590:INFO:           streamlit: Not installed
2023-04-19 16:35:24,590:INFO:             prophet: Not installed
2023-04-19 16:35:24,590:INFO:None
2023-04-19 16:35:24,590:INFO:Set up data.
2023-04-19 16:35:24,704:INFO:Set up train/test split.
2023-04-19 16:35:24,748:INFO:Set up index.
2023-04-19 16:35:24,748:INFO:Set up folding strategy.
2023-04-19 16:35:24,748:INFO:Assigning column types.
2023-04-19 16:35:24,769:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-19 16:35:24,776:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-19 16:35:24,794:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-19 16:35:24,807:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-19 16:35:25,038:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-19 16:35:25,181:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-19 16:35:25,182:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:35:25,228:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:35:25,230:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-19 16:35:25,244:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-19 16:35:25,254:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-19 16:35:25,395:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-19 16:35:25,512:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-19 16:35:25,513:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:35:25,513:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:35:25,514:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-19 16:35:25,598:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-19 16:35:25,632:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-19 16:35:25,969:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-19 16:35:26,059:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-19 16:35:26,059:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:35:26,060:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:35:26,068:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-19 16:35:26,077:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-19 16:35:26,191:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-19 16:35:26,272:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-19 16:35:26,273:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:35:26,273:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:35:26,273:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-19 16:35:26,289:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-19 16:35:26,462:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-19 16:35:26,553:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-19 16:35:26,553:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:35:26,554:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:35:26,571:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-19 16:35:26,685:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-19 16:35:26,754:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-19 16:35:26,754:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:35:26,754:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:35:26,754:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-19 16:35:26,900:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-19 16:35:27,001:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-19 16:35:27,001:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:35:27,001:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:35:27,205:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-19 16:35:27,335:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-19 16:35:27,337:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:35:27,338:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:35:27,339:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-19 16:35:27,471:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-19 16:35:27,549:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:35:27,549:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:35:27,666:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-19 16:35:27,733:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:35:27,733:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:35:27,733:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-19 16:35:27,920:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:35:27,920:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:35:28,150:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:35:28,150:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:35:28,150:INFO:Preparing preprocessing pipeline...
2023-04-19 16:35:28,150:INFO:Set up simple imputation.
2023-04-19 16:35:28,166:INFO:Set up column name cleaning.
2023-04-19 16:35:28,820:INFO:Finished creating preprocessing pipeline.
2023-04-19 16:35:28,836:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['LotFrontage', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'MasVnrArea', 'BsmtFinSF1',
                                             'BsmtFinSF2', 'BsmtUnfSF',
                                             'TotalBsmtSF', '1stFlrSF',
                                             '2ndFlrSF', 'LowQualFinSF',
                                             'GrLivArea', 'BsmtFullBath',
                                             'Bsmt...
                                             'KitchenAbvGr', 'TotRmsAbvGrd',
                                             'Fireplaces', 'GarageYrBlt',
                                             'GarageCars', 'GarageArea',
                                             'WoodDeckSF', 'OpenPorchSF',
                                             'EnclosedPorch', '3SsnPorch', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-19 16:35:28,836:INFO:Creating final display dataframe.
2023-04-19 16:35:29,126:INFO:Setup _display_container:                     Description             Value
0                    Session id              6913
1                        Target         SalePrice
2                   Target type        Regression
3           Original data shape       (1460, 318)
4        Transformed data shape       (1460, 318)
5   Transformed train set shape       (1021, 318)
6    Transformed test set shape        (439, 318)
7              Numeric features               317
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              d527
2023-04-19 16:35:29,425:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:35:29,425:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:35:29,641:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:35:29,642:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:35:29,643:INFO:setup() successfully completed in 5.97s...............
2023-04-19 16:47:33,683:INFO:PyCaret RegressionExperiment
2023-04-19 16:47:33,684:INFO:Logging name: reg-default-name
2023-04-19 16:47:33,684:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-19 16:47:33,684:INFO:version 3.0.0
2023-04-19 16:47:33,684:INFO:Initializing setup()
2023-04-19 16:47:33,684:INFO:self.USI: 92b0
2023-04-19 16:47:33,685:INFO:self._variable_keys: {'y_train', 'X_train', 'pipeline', '_available_plots', 'data', 'seed', 'transform_target_param', 'X_test', 'target_param', 'logging_param', 'fold_generator', 'fold_shuffle_param', '_ml_usecase', 'X', 'USI', 'gpu_param', 'html_param', 'log_plots_param', 'idx', 'exp_id', 'y', 'exp_name_log', 'n_jobs_param', 'memory', 'gpu_n_jobs_param', 'y_test', 'fold_groups_param'}
2023-04-19 16:47:33,685:INFO:Checking environment
2023-04-19 16:47:33,685:INFO:python_version: 3.9.13
2023-04-19 16:47:33,685:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-19 16:47:33,686:INFO:machine: AMD64
2023-04-19 16:47:33,686:INFO:platform: Windows-10-10.0.18363-SP0
2023-04-19 16:47:33,686:INFO:Memory: svmem(total=8488050688, available=2843107328, percent=66.5, used=5644943360, free=2843107328)
2023-04-19 16:47:33,686:INFO:Physical Core: 2
2023-04-19 16:47:33,686:INFO:Logical Core: 4
2023-04-19 16:47:33,686:INFO:Checking libraries
2023-04-19 16:47:33,686:INFO:System:
2023-04-19 16:47:33,686:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-19 16:47:33,686:INFO:executable: E:\python\Anaconda3\python.exe
2023-04-19 16:47:33,687:INFO:   machine: Windows-10-10.0.18363-SP0
2023-04-19 16:47:33,687:INFO:PyCaret required dependencies:
2023-04-19 16:47:33,687:INFO:                 pip: 22.2.2
2023-04-19 16:47:33,687:INFO:          setuptools: 63.4.1
2023-04-19 16:47:33,687:INFO:             pycaret: 3.0.0
2023-04-19 16:47:33,687:INFO:             IPython: 7.31.1
2023-04-19 16:47:33,687:INFO:          ipywidgets: 7.6.5
2023-04-19 16:47:33,687:INFO:                tqdm: 4.64.1
2023-04-19 16:47:33,687:INFO:               numpy: 1.21.5
2023-04-19 16:47:33,688:INFO:              pandas: 1.4.4
2023-04-19 16:47:33,688:INFO:              jinja2: 2.11.3
2023-04-19 16:47:33,688:INFO:               scipy: 1.9.1
2023-04-19 16:47:33,688:INFO:              joblib: 1.2.0
2023-04-19 16:47:33,688:INFO:             sklearn: 1.0.2
2023-04-19 16:47:33,688:INFO:                pyod: 1.0.9
2023-04-19 16:47:33,688:INFO:            imblearn: 0.10.1
2023-04-19 16:47:33,688:INFO:   category_encoders: 2.6.0
2023-04-19 16:47:33,689:INFO:            lightgbm: 3.3.5
2023-04-19 16:47:33,689:INFO:               numba: 0.55.1
2023-04-19 16:47:33,689:INFO:            requests: 2.28.1
2023-04-19 16:47:33,689:INFO:          matplotlib: 3.5.2
2023-04-19 16:47:33,689:INFO:          scikitplot: 0.3.7
2023-04-19 16:47:33,689:INFO:         yellowbrick: 1.5
2023-04-19 16:47:33,689:INFO:              plotly: 5.9.0
2023-04-19 16:47:33,690:INFO:             kaleido: 0.2.1
2023-04-19 16:47:33,690:INFO:         statsmodels: 0.13.2
2023-04-19 16:47:33,690:INFO:              sktime: 0.17.1
2023-04-19 16:47:33,690:INFO:               tbats: 1.1.3
2023-04-19 16:47:33,690:INFO:            pmdarima: 2.0.3
2023-04-19 16:47:33,690:INFO:              psutil: 5.9.0
2023-04-19 16:47:33,691:INFO:PyCaret optional dependencies:
2023-04-19 16:47:33,691:INFO:                shap: Not installed
2023-04-19 16:47:33,691:INFO:           interpret: Not installed
2023-04-19 16:47:33,691:INFO:                umap: Not installed
2023-04-19 16:47:33,691:INFO:    pandas_profiling: Not installed
2023-04-19 16:47:33,691:INFO:  explainerdashboard: Not installed
2023-04-19 16:47:33,691:INFO:             autoviz: Not installed
2023-04-19 16:47:33,691:INFO:           fairlearn: Not installed
2023-04-19 16:47:33,691:INFO:             xgboost: Not installed
2023-04-19 16:47:33,691:INFO:            catboost: Not installed
2023-04-19 16:47:33,692:INFO:              kmodes: Not installed
2023-04-19 16:47:33,692:INFO:             mlxtend: Not installed
2023-04-19 16:47:33,692:INFO:       statsforecast: Not installed
2023-04-19 16:47:33,692:INFO:        tune_sklearn: Not installed
2023-04-19 16:47:33,692:INFO:                 ray: Not installed
2023-04-19 16:47:33,692:INFO:            hyperopt: Not installed
2023-04-19 16:47:33,692:INFO:              optuna: Not installed
2023-04-19 16:47:33,692:INFO:               skopt: Not installed
2023-04-19 16:47:33,693:INFO:              mlflow: Not installed
2023-04-19 16:47:33,693:INFO:              gradio: Not installed
2023-04-19 16:47:33,693:INFO:             fastapi: Not installed
2023-04-19 16:47:33,693:INFO:             uvicorn: Not installed
2023-04-19 16:47:33,693:INFO:              m2cgen: Not installed
2023-04-19 16:47:33,693:INFO:           evidently: Not installed
2023-04-19 16:47:33,693:INFO:               fugue: Not installed
2023-04-19 16:47:33,693:INFO:           streamlit: Not installed
2023-04-19 16:47:33,693:INFO:             prophet: Not installed
2023-04-19 16:47:33,693:INFO:None
2023-04-19 16:47:33,693:INFO:Set up data.
2023-04-19 16:47:33,894:INFO:Set up train/test split.
2023-04-19 16:47:33,906:INFO:Set up index.
2023-04-19 16:47:33,906:INFO:Set up folding strategy.
2023-04-19 16:47:33,906:INFO:Assigning column types.
2023-04-19 16:47:33,921:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-19 16:47:33,921:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-19 16:47:33,937:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-19 16:47:33,937:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-19 16:47:34,062:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-19 16:47:34,172:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-19 16:47:34,172:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:47:34,172:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:47:34,172:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-19 16:47:34,188:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-19 16:47:34,188:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-19 16:47:34,332:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-19 16:47:34,410:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-19 16:47:34,410:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:47:34,410:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:47:34,410:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-19 16:47:34,425:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-19 16:47:34,425:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-19 16:47:34,536:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-19 16:47:34,614:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-19 16:47:34,614:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:47:34,614:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:47:34,630:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-19 16:47:34,630:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-19 16:47:34,737:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-19 16:47:34,826:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-19 16:47:34,828:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:47:34,829:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:47:34,830:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-19 16:47:34,864:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-19 16:47:35,009:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-19 16:47:35,105:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-19 16:47:35,105:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:47:35,105:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:47:35,135:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-19 16:47:35,290:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-19 16:47:35,374:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-19 16:47:35,375:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:47:35,375:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:47:35,376:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-19 16:47:35,507:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-19 16:47:35,584:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-19 16:47:35,584:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:47:35,585:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:47:35,682:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-19 16:47:35,773:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-19 16:47:35,774:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:47:35,775:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:47:35,775:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-19 16:47:35,905:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-19 16:47:35,970:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:47:35,970:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:47:36,095:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-19 16:47:36,157:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:47:36,157:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:47:36,157:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-19 16:47:36,355:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:47:36,355:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:47:36,553:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:47:36,553:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:47:36,553:INFO:Preparing preprocessing pipeline...
2023-04-19 16:47:36,553:INFO:Set up simple imputation.
2023-04-19 16:47:36,553:INFO:Set up column name cleaning.
2023-04-19 16:47:36,629:INFO:Finished creating preprocessing pipeline.
2023-04-19 16:47:36,639:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['LotFrontage', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'MasVnrArea', 'BsmtFinSF1',
                                             'BsmtFinSF2', 'BsmtUnfSF',
                                             'TotalBsmtSF', '1stFlrSF',
                                             '2ndFlrSF', 'LowQualFinSF',
                                             'GrLivArea', 'BsmtFullBath',
                                             'Bsmt...
                                             'KitchenAbvGr', 'TotRmsAbvGrd',
                                             'Fireplaces', 'GarageYrBlt',
                                             'GarageCars', 'GarageArea',
                                             'WoodDeckSF', 'OpenPorchSF',
                                             'EnclosedPorch', '3SsnPorch', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-19 16:47:36,639:INFO:Creating final display dataframe.
2023-04-19 16:47:36,919:INFO:Setup _display_container:                     Description             Value
0                    Session id              3965
1                        Target         SalePrice
2                   Target type        Regression
3           Original data shape       (1460, 318)
4        Transformed data shape       (1460, 318)
5   Transformed train set shape       (1021, 318)
6    Transformed test set shape        (439, 318)
7              Numeric features               317
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              92b0
2023-04-19 16:47:37,131:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:47:37,131:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:47:37,314:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:47:37,314:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:47:37,314:INFO:setup() successfully completed in 3.64s...............
2023-04-19 16:50:57,720:INFO:PyCaret RegressionExperiment
2023-04-19 16:50:57,720:INFO:Logging name: reg-default-name
2023-04-19 16:50:57,720:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-19 16:50:57,721:INFO:version 3.0.0
2023-04-19 16:50:57,721:INFO:Initializing setup()
2023-04-19 16:50:57,721:INFO:self.USI: a3d6
2023-04-19 16:50:57,721:INFO:self._variable_keys: {'y_train', 'X_train', 'pipeline', '_available_plots', 'data', 'seed', 'transform_target_param', 'X_test', 'target_param', 'logging_param', 'fold_generator', 'fold_shuffle_param', '_ml_usecase', 'X', 'USI', 'gpu_param', 'html_param', 'log_plots_param', 'idx', 'exp_id', 'y', 'exp_name_log', 'n_jobs_param', 'memory', 'gpu_n_jobs_param', 'y_test', 'fold_groups_param'}
2023-04-19 16:50:57,721:INFO:Checking environment
2023-04-19 16:50:57,721:INFO:python_version: 3.9.13
2023-04-19 16:50:57,721:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-19 16:50:57,721:INFO:machine: AMD64
2023-04-19 16:50:57,721:INFO:platform: Windows-10-10.0.18363-SP0
2023-04-19 16:50:57,721:INFO:Memory: svmem(total=8488050688, available=2908667904, percent=65.7, used=5579382784, free=2908667904)
2023-04-19 16:50:57,721:INFO:Physical Core: 2
2023-04-19 16:50:57,722:INFO:Logical Core: 4
2023-04-19 16:50:57,722:INFO:Checking libraries
2023-04-19 16:50:57,722:INFO:System:
2023-04-19 16:50:57,722:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-19 16:50:57,722:INFO:executable: E:\python\Anaconda3\python.exe
2023-04-19 16:50:57,722:INFO:   machine: Windows-10-10.0.18363-SP0
2023-04-19 16:50:57,722:INFO:PyCaret required dependencies:
2023-04-19 16:50:57,722:INFO:                 pip: 22.2.2
2023-04-19 16:50:57,722:INFO:          setuptools: 63.4.1
2023-04-19 16:50:57,722:INFO:             pycaret: 3.0.0
2023-04-19 16:50:57,722:INFO:             IPython: 7.31.1
2023-04-19 16:50:57,722:INFO:          ipywidgets: 7.6.5
2023-04-19 16:50:57,723:INFO:                tqdm: 4.64.1
2023-04-19 16:50:57,723:INFO:               numpy: 1.21.5
2023-04-19 16:50:57,723:INFO:              pandas: 1.4.4
2023-04-19 16:50:57,723:INFO:              jinja2: 2.11.3
2023-04-19 16:50:57,723:INFO:               scipy: 1.9.1
2023-04-19 16:50:57,723:INFO:              joblib: 1.2.0
2023-04-19 16:50:57,723:INFO:             sklearn: 1.0.2
2023-04-19 16:50:57,723:INFO:                pyod: 1.0.9
2023-04-19 16:50:57,723:INFO:            imblearn: 0.10.1
2023-04-19 16:50:57,723:INFO:   category_encoders: 2.6.0
2023-04-19 16:50:57,723:INFO:            lightgbm: 3.3.5
2023-04-19 16:50:57,723:INFO:               numba: 0.55.1
2023-04-19 16:50:57,723:INFO:            requests: 2.28.1
2023-04-19 16:50:57,724:INFO:          matplotlib: 3.5.2
2023-04-19 16:50:57,724:INFO:          scikitplot: 0.3.7
2023-04-19 16:50:57,724:INFO:         yellowbrick: 1.5
2023-04-19 16:50:57,724:INFO:              plotly: 5.9.0
2023-04-19 16:50:57,724:INFO:             kaleido: 0.2.1
2023-04-19 16:50:57,724:INFO:         statsmodels: 0.13.2
2023-04-19 16:50:57,724:INFO:              sktime: 0.17.1
2023-04-19 16:50:57,724:INFO:               tbats: 1.1.3
2023-04-19 16:50:57,724:INFO:            pmdarima: 2.0.3
2023-04-19 16:50:57,724:INFO:              psutil: 5.9.0
2023-04-19 16:50:57,724:INFO:PyCaret optional dependencies:
2023-04-19 16:50:57,724:INFO:                shap: Not installed
2023-04-19 16:50:57,724:INFO:           interpret: Not installed
2023-04-19 16:50:57,725:INFO:                umap: Not installed
2023-04-19 16:50:57,725:INFO:    pandas_profiling: Not installed
2023-04-19 16:50:57,725:INFO:  explainerdashboard: Not installed
2023-04-19 16:50:57,725:INFO:             autoviz: Not installed
2023-04-19 16:50:57,725:INFO:           fairlearn: Not installed
2023-04-19 16:50:57,725:INFO:             xgboost: Not installed
2023-04-19 16:50:57,725:INFO:            catboost: Not installed
2023-04-19 16:50:57,725:INFO:              kmodes: Not installed
2023-04-19 16:50:57,725:INFO:             mlxtend: Not installed
2023-04-19 16:50:57,725:INFO:       statsforecast: Not installed
2023-04-19 16:50:57,725:INFO:        tune_sklearn: Not installed
2023-04-19 16:50:57,725:INFO:                 ray: Not installed
2023-04-19 16:50:57,725:INFO:            hyperopt: Not installed
2023-04-19 16:50:57,726:INFO:              optuna: Not installed
2023-04-19 16:50:57,726:INFO:               skopt: Not installed
2023-04-19 16:50:57,726:INFO:              mlflow: Not installed
2023-04-19 16:50:57,726:INFO:              gradio: Not installed
2023-04-19 16:50:57,726:INFO:             fastapi: Not installed
2023-04-19 16:50:57,726:INFO:             uvicorn: Not installed
2023-04-19 16:50:57,726:INFO:              m2cgen: Not installed
2023-04-19 16:50:57,726:INFO:           evidently: Not installed
2023-04-19 16:50:57,726:INFO:               fugue: Not installed
2023-04-19 16:50:57,726:INFO:           streamlit: Not installed
2023-04-19 16:50:57,726:INFO:             prophet: Not installed
2023-04-19 16:50:57,726:INFO:None
2023-04-19 16:50:57,726:INFO:Set up data.
2023-04-19 16:50:57,881:INFO:Set up train/test split.
2023-04-19 16:50:57,896:INFO:Set up index.
2023-04-19 16:50:57,896:INFO:Set up folding strategy.
2023-04-19 16:50:57,896:INFO:Assigning column types.
2023-04-19 16:50:57,928:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-19 16:50:57,928:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-19 16:50:57,928:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-19 16:50:57,943:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-19 16:50:58,078:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-19 16:50:58,197:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-19 16:50:58,197:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:50:58,197:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:50:58,197:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-19 16:50:58,197:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-19 16:50:58,213:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-19 16:50:58,335:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-19 16:50:58,446:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-19 16:50:58,446:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:50:58,446:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:50:58,446:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-19 16:50:58,446:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-19 16:50:58,469:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-19 16:50:58,590:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-19 16:50:58,668:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-19 16:50:58,668:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:50:58,668:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:50:58,668:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-19 16:50:58,684:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-19 16:50:58,802:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-19 16:50:58,922:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-19 16:50:58,924:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:50:58,924:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:50:58,925:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-19 16:50:58,931:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-19 16:50:59,098:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-19 16:50:59,183:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-19 16:50:59,184:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:50:59,185:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:50:59,204:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-19 16:50:59,343:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-19 16:50:59,457:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-19 16:50:59,459:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:50:59,459:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:50:59,460:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-19 16:50:59,644:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-19 16:50:59,761:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-19 16:50:59,776:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:50:59,776:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:51:00,044:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-19 16:51:00,169:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-19 16:51:00,169:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:51:00,169:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:51:00,169:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-19 16:51:00,352:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-19 16:51:00,480:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:51:00,480:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:51:00,683:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-19 16:51:00,808:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:51:00,808:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:51:00,808:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-19 16:51:01,090:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:51:01,090:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:51:01,383:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:51:01,383:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:51:01,383:INFO:Preparing preprocessing pipeline...
2023-04-19 16:51:01,383:INFO:Set up simple imputation.
2023-04-19 16:51:01,383:INFO:Set up column name cleaning.
2023-04-19 16:51:01,480:INFO:Finished creating preprocessing pipeline.
2023-04-19 16:51:01,497:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['LotFrontage', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'MasVnrArea', 'BsmtFinSF1',
                                             'BsmtFinSF2', 'BsmtUnfSF',
                                             'TotalBsmtSF', '1stFlrSF',
                                             '2ndFlrSF', 'LowQualFinSF',
                                             'GrLivArea', 'BsmtFullBath',
                                             'Bsmt...
                                             'KitchenAbvGr', 'TotRmsAbvGrd',
                                             'Fireplaces', 'GarageYrBlt',
                                             'GarageCars', 'GarageArea',
                                             'WoodDeckSF', 'OpenPorchSF',
                                             'EnclosedPorch', '3SsnPorch', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-19 16:51:01,497:INFO:Creating final display dataframe.
2023-04-19 16:51:01,919:INFO:Setup _display_container:                     Description             Value
0                    Session id              3117
1                        Target         SalePrice
2                   Target type        Regression
3           Original data shape       (1460, 318)
4        Transformed data shape       (1460, 318)
5   Transformed train set shape       (1021, 318)
6    Transformed test set shape        (439, 318)
7              Numeric features               317
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              a3d6
2023-04-19 16:51:02,197:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:51:02,197:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:51:02,464:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:51:02,464:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-19 16:51:02,464:INFO:setup() successfully completed in 4.75s...............
2023-04-19 16:51:50,507:INFO:Initializing compare_models()
2023-04-19 16:51:50,508:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000151F22FBF40>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000151F22FBF40>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-19 16:51:50,508:INFO:Checking exceptions
2023-04-19 16:51:50,516:INFO:Preparing display monitor
2023-04-19 16:51:50,591:INFO:Initializing Linear Regression
2023-04-19 16:51:50,592:INFO:Total runtime is 1.6697247823079427e-05 minutes
2023-04-19 16:51:50,601:INFO:SubProcess create_model() called ==================================
2023-04-19 16:51:50,602:INFO:Initializing create_model()
2023-04-19 16:51:50,602:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000151F22FBF40>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000151F24339D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-19 16:51:50,603:INFO:Checking exceptions
2023-04-19 16:51:50,603:INFO:Importing libraries
2023-04-19 16:51:50,604:INFO:Copying training dataset
2023-04-19 16:51:50,627:INFO:Defining folds
2023-04-19 16:51:50,628:INFO:Declaring metric variables
2023-04-19 16:51:50,633:INFO:Importing untrained model
2023-04-19 16:51:50,640:INFO:Linear Regression Imported successfully
2023-04-19 16:51:50,662:INFO:Starting cross validation
2023-04-19 16:51:50,819:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 16:52:02,993:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_9ed980457540437c9aaa9eab02842731\9400-1451475006128-3930932db9b046d1a6266608a8835928.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:02,994:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_9ed980457540437c9aaa9eab02842731\9400-1451475006128-3930932db9b046d1a6266608a8835928.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:02,994:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_9ed980457540437c9aaa9eab02842731\9400-1451475006128-3930932db9b046d1a6266608a8835928.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:03,329:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_9ed980457540437c9aaa9eab02842731\9400-1451475006128-3930932db9b046d1a6266608a8835928.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:04,905:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_9ed980457540437c9aaa9eab02842731\9400-1451475006128-3930932db9b046d1a6266608a8835928.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:04,916:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_9ed980457540437c9aaa9eab02842731\9400-1451475006128-3930932db9b046d1a6266608a8835928.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:04,952:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_9ed980457540437c9aaa9eab02842731\9400-1451475006128-3930932db9b046d1a6266608a8835928.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:05,186:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 16:52:05,316:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_9ed980457540437c9aaa9eab02842731\9400-1451475006128-3930932db9b046d1a6266608a8835928.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:05,404:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_9ed980457540437c9aaa9eab02842731\9400-1451475006128-3930932db9b046d1a6266608a8835928.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:05,931:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_9ed980457540437c9aaa9eab02842731\9400-1451475006128-3930932db9b046d1a6266608a8835928.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:06,814:INFO:Calculating mean and std
2023-04-19 16:52:06,819:INFO:Creating metrics dataframe
2023-04-19 16:52:06,847:INFO:Uploading results into container
2023-04-19 16:52:06,848:INFO:Uploading model into container now
2023-04-19 16:52:06,851:INFO:_master_model_container: 1
2023-04-19 16:52:06,851:INFO:_display_container: 2
2023-04-19 16:52:06,852:INFO:LinearRegression(n_jobs=-1)
2023-04-19 16:52:06,852:INFO:create_model() successfully completed......................................
2023-04-19 16:52:06,992:INFO:SubProcess create_model() end ==================================
2023-04-19 16:52:06,992:INFO:Creating metrics dataframe
2023-04-19 16:52:07,021:INFO:Initializing Lasso Regression
2023-04-19 16:52:07,021:INFO:Total runtime is 0.2738352497418722 minutes
2023-04-19 16:52:07,029:INFO:SubProcess create_model() called ==================================
2023-04-19 16:52:07,030:INFO:Initializing create_model()
2023-04-19 16:52:07,030:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000151F22FBF40>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000151F24339D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-19 16:52:07,031:INFO:Checking exceptions
2023-04-19 16:52:07,031:INFO:Importing libraries
2023-04-19 16:52:07,032:INFO:Copying training dataset
2023-04-19 16:52:07,060:INFO:Defining folds
2023-04-19 16:52:07,061:INFO:Declaring metric variables
2023-04-19 16:52:07,069:INFO:Importing untrained model
2023-04-19 16:52:07,079:INFO:Lasso Regression Imported successfully
2023-04-19 16:52:07,098:INFO:Starting cross validation
2023-04-19 16:52:07,105:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 16:52:07,173:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_cbe66ae9e54e44d99f96c4d7e5596900\9400-1451475006128-1572b72e300341f89f58207c1fa24409.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:07,191:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_cbe66ae9e54e44d99f96c4d7e5596900\9400-1451475006128-1572b72e300341f89f58207c1fa24409.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:07,213:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_cbe66ae9e54e44d99f96c4d7e5596900\9400-1451475006128-1572b72e300341f89f58207c1fa24409.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:07,235:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_cbe66ae9e54e44d99f96c4d7e5596900\9400-1451475006128-1572b72e300341f89f58207c1fa24409.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:08,121:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 16:52:08,815:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 16:52:08,837:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 16:52:08,840:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 16:52:08,891:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_cbe66ae9e54e44d99f96c4d7e5596900\9400-1451475006128-1572b72e300341f89f58207c1fa24409.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:08,912:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_cbe66ae9e54e44d99f96c4d7e5596900\9400-1451475006128-1572b72e300341f89f58207c1fa24409.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:08,965:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 16:52:08,990:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_cbe66ae9e54e44d99f96c4d7e5596900\9400-1451475006128-1572b72e300341f89f58207c1fa24409.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:09,111:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_cbe66ae9e54e44d99f96c4d7e5596900\9400-1451475006128-1572b72e300341f89f58207c1fa24409.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:10,028:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 16:52:10,038:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 16:52:10,131:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_cbe66ae9e54e44d99f96c4d7e5596900\9400-1451475006128-1572b72e300341f89f58207c1fa24409.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:10,139:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 16:52:10,196:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_cbe66ae9e54e44d99f96c4d7e5596900\9400-1451475006128-1572b72e300341f89f58207c1fa24409.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:10,208:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 16:52:10,675:INFO:Calculating mean and std
2023-04-19 16:52:10,679:INFO:Creating metrics dataframe
2023-04-19 16:52:10,724:INFO:Uploading results into container
2023-04-19 16:52:10,725:INFO:Uploading model into container now
2023-04-19 16:52:10,725:INFO:_master_model_container: 2
2023-04-19 16:52:10,725:INFO:_display_container: 2
2023-04-19 16:52:10,726:INFO:Lasso(random_state=3117)
2023-04-19 16:52:10,726:INFO:create_model() successfully completed......................................
2023-04-19 16:52:10,873:INFO:SubProcess create_model() end ==================================
2023-04-19 16:52:10,873:INFO:Creating metrics dataframe
2023-04-19 16:52:10,892:INFO:Initializing Ridge Regression
2023-04-19 16:52:10,892:INFO:Total runtime is 0.33835029204686484 minutes
2023-04-19 16:52:10,900:INFO:SubProcess create_model() called ==================================
2023-04-19 16:52:10,901:INFO:Initializing create_model()
2023-04-19 16:52:10,901:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000151F22FBF40>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000151F24339D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-19 16:52:10,901:INFO:Checking exceptions
2023-04-19 16:52:10,902:INFO:Importing libraries
2023-04-19 16:52:10,902:INFO:Copying training dataset
2023-04-19 16:52:10,935:INFO:Defining folds
2023-04-19 16:52:10,936:INFO:Declaring metric variables
2023-04-19 16:52:10,946:INFO:Importing untrained model
2023-04-19 16:52:10,958:INFO:Ridge Regression Imported successfully
2023-04-19 16:52:10,978:INFO:Starting cross validation
2023-04-19 16:52:10,986:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 16:52:11,061:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_e2e6c115fffc4b49987415ebfddd7dc4\9400-1451475006128-c5929aade40b4f94b8bd0e269099efdf.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:11,086:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_e2e6c115fffc4b49987415ebfddd7dc4\9400-1451475006128-c5929aade40b4f94b8bd0e269099efdf.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:11,108:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_e2e6c115fffc4b49987415ebfddd7dc4\9400-1451475006128-c5929aade40b4f94b8bd0e269099efdf.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:11,129:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_e2e6c115fffc4b49987415ebfddd7dc4\9400-1451475006128-c5929aade40b4f94b8bd0e269099efdf.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:12,195:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_e2e6c115fffc4b49987415ebfddd7dc4\9400-1451475006128-c5929aade40b4f94b8bd0e269099efdf.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:12,227:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_e2e6c115fffc4b49987415ebfddd7dc4\9400-1451475006128-c5929aade40b4f94b8bd0e269099efdf.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:12,260:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_e2e6c115fffc4b49987415ebfddd7dc4\9400-1451475006128-c5929aade40b4f94b8bd0e269099efdf.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:12,676:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_e2e6c115fffc4b49987415ebfddd7dc4\9400-1451475006128-c5929aade40b4f94b8bd0e269099efdf.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:12,790:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_e2e6c115fffc4b49987415ebfddd7dc4\9400-1451475006128-c5929aade40b4f94b8bd0e269099efdf.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:13,133:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_e2e6c115fffc4b49987415ebfddd7dc4\9400-1451475006128-c5929aade40b4f94b8bd0e269099efdf.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:13,530:INFO:Calculating mean and std
2023-04-19 16:52:13,534:INFO:Creating metrics dataframe
2023-04-19 16:52:13,576:INFO:Uploading results into container
2023-04-19 16:52:13,577:INFO:Uploading model into container now
2023-04-19 16:52:13,578:INFO:_master_model_container: 3
2023-04-19 16:52:13,578:INFO:_display_container: 2
2023-04-19 16:52:13,578:INFO:Ridge(random_state=3117)
2023-04-19 16:52:13,578:INFO:create_model() successfully completed......................................
2023-04-19 16:52:13,693:INFO:SubProcess create_model() end ==================================
2023-04-19 16:52:13,693:INFO:Creating metrics dataframe
2023-04-19 16:52:13,710:INFO:Initializing Elastic Net
2023-04-19 16:52:13,711:INFO:Total runtime is 0.38533571163813274 minutes
2023-04-19 16:52:13,721:INFO:SubProcess create_model() called ==================================
2023-04-19 16:52:13,721:INFO:Initializing create_model()
2023-04-19 16:52:13,721:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000151F22FBF40>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000151F24339D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-19 16:52:13,722:INFO:Checking exceptions
2023-04-19 16:52:13,722:INFO:Importing libraries
2023-04-19 16:52:13,722:INFO:Copying training dataset
2023-04-19 16:52:13,743:INFO:Defining folds
2023-04-19 16:52:13,743:INFO:Declaring metric variables
2023-04-19 16:52:13,756:INFO:Importing untrained model
2023-04-19 16:52:13,769:INFO:Elastic Net Imported successfully
2023-04-19 16:52:13,787:INFO:Starting cross validation
2023-04-19 16:52:13,795:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 16:52:13,863:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_d23613e62b414ab5adb101f131dde67b\9400-1451475006128-16aedaed9aa24065aeac139a482da8b3.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:13,879:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_d23613e62b414ab5adb101f131dde67b\9400-1451475006128-16aedaed9aa24065aeac139a482da8b3.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:13,897:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_d23613e62b414ab5adb101f131dde67b\9400-1451475006128-16aedaed9aa24065aeac139a482da8b3.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:13,938:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_d23613e62b414ab5adb101f131dde67b\9400-1451475006128-16aedaed9aa24065aeac139a482da8b3.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:14,326:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_d23613e62b414ab5adb101f131dde67b\9400-1451475006128-16aedaed9aa24065aeac139a482da8b3.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:14,389:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_d23613e62b414ab5adb101f131dde67b\9400-1451475006128-16aedaed9aa24065aeac139a482da8b3.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:14,742:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_d23613e62b414ab5adb101f131dde67b\9400-1451475006128-16aedaed9aa24065aeac139a482da8b3.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:14,815:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_d23613e62b414ab5adb101f131dde67b\9400-1451475006128-16aedaed9aa24065aeac139a482da8b3.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:14,836:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_d23613e62b414ab5adb101f131dde67b\9400-1451475006128-16aedaed9aa24065aeac139a482da8b3.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:15,239:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_d23613e62b414ab5adb101f131dde67b\9400-1451475006128-16aedaed9aa24065aeac139a482da8b3.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:15,795:INFO:Calculating mean and std
2023-04-19 16:52:15,801:INFO:Creating metrics dataframe
2023-04-19 16:52:15,868:INFO:Uploading results into container
2023-04-19 16:52:15,869:INFO:Uploading model into container now
2023-04-19 16:52:15,870:INFO:_master_model_container: 4
2023-04-19 16:52:15,870:INFO:_display_container: 2
2023-04-19 16:52:15,871:INFO:ElasticNet(random_state=3117)
2023-04-19 16:52:15,871:INFO:create_model() successfully completed......................................
2023-04-19 16:52:15,997:INFO:SubProcess create_model() end ==================================
2023-04-19 16:52:15,997:INFO:Creating metrics dataframe
2023-04-19 16:52:16,042:INFO:Initializing Least Angle Regression
2023-04-19 16:52:16,042:INFO:Total runtime is 0.42419244050979615 minutes
2023-04-19 16:52:16,053:INFO:SubProcess create_model() called ==================================
2023-04-19 16:52:16,053:INFO:Initializing create_model()
2023-04-19 16:52:16,054:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000151F22FBF40>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000151F24339D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-19 16:52:16,054:INFO:Checking exceptions
2023-04-19 16:52:16,055:INFO:Importing libraries
2023-04-19 16:52:16,055:INFO:Copying training dataset
2023-04-19 16:52:16,080:INFO:Defining folds
2023-04-19 16:52:16,081:INFO:Declaring metric variables
2023-04-19 16:52:16,089:INFO:Importing untrained model
2023-04-19 16:52:16,106:INFO:Least Angle Regression Imported successfully
2023-04-19 16:52:16,124:INFO:Starting cross validation
2023-04-19 16:52:16,129:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 16:52:16,184:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_d9ad40bac0f04110b7f49827a9beb7a8\9400-1451475006128-290cbb65e63a495687d9f50eefa49247.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:16,202:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_d9ad40bac0f04110b7f49827a9beb7a8\9400-1451475006128-290cbb65e63a495687d9f50eefa49247.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:16,222:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_d9ad40bac0f04110b7f49827a9beb7a8\9400-1451475006128-290cbb65e63a495687d9f50eefa49247.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:16,245:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_d9ad40bac0f04110b7f49827a9beb7a8\9400-1451475006128-290cbb65e63a495687d9f50eefa49247.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:16,407:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-19 16:52:16,409:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-19 16:52:16,411:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-19 16:52:16,420:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-19 16:52:16,610:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=6.155e-04, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-19 16:52:16,612:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 90 iterations, i.e. alpha=1.583e-04, with an active set of 87 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-19 16:52:16,637:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=2.783e-04, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-19 16:52:16,658:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=3.949e-04, with an active set of 112 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-19 16:52:16,685:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:744: RuntimeWarning: overflow encountered in true_divide
  z = -coef[active] / (least_squares + tiny32)

2023-04-19 16:52:17,563:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-04-19 16:52:17,563:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-04-19 16:52:17,564:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-04-19 16:52:17,564:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-04-19 16:52:17,566:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:805: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-04-19 16:52:17,566:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:805: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-04-19 16:52:17,564:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-04-19 16:52:17,569:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:805: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-04-19 16:52:17,642:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_d9ad40bac0f04110b7f49827a9beb7a8\9400-1451475006128-290cbb65e63a495687d9f50eefa49247.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:17,663:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_d9ad40bac0f04110b7f49827a9beb7a8\9400-1451475006128-290cbb65e63a495687d9f50eefa49247.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:17,684:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_d9ad40bac0f04110b7f49827a9beb7a8\9400-1451475006128-290cbb65e63a495687d9f50eefa49247.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:17,704:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_d9ad40bac0f04110b7f49827a9beb7a8\9400-1451475006128-290cbb65e63a495687d9f50eefa49247.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:17,867:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-19 16:52:17,872:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-19 16:52:17,926:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-19 16:52:17,926:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-19 16:52:17,962:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:744: RuntimeWarning: overflow encountered in true_divide
  z = -coef[active] / (least_squares + tiny32)

2023-04-19 16:52:17,992:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=3.797e-04, with an active set of 61 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-19 16:52:18,279:WARNING:E:\python\Anaconda3\lib\site-packages\numpy\core\fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-04-19 16:52:18,279:WARNING:E:\python\Anaconda3\lib\site-packages\numpy\core\fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-04-19 16:52:18,280:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:735: RuntimeWarning: overflow encountered in true_divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-04-19 16:52:18,280:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:735: RuntimeWarning: overflow encountered in true_divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-04-19 16:52:18,280:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:739: RuntimeWarning: overflow encountered in true_divide
  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny32))

2023-04-19 16:52:18,280:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:739: RuntimeWarning: overflow encountered in true_divide
  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny32))

2023-04-19 16:52:18,280:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:740: RuntimeWarning: divide by zero encountered in true_divide
  gamma_ = min(g1, g2, C / AA)

2023-04-19 16:52:18,280:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:740: RuntimeWarning: divide by zero encountered in true_divide
  gamma_ = min(g1, g2, C / AA)

2023-04-19 16:52:18,280:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:744: RuntimeWarning: overflow encountered in true_divide
  z = -coef[active] / (least_squares + tiny32)

2023-04-19 16:52:18,280:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:744: RuntimeWarning: overflow encountered in true_divide
  z = -coef[active] / (least_squares + tiny32)

2023-04-19 16:52:18,796:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-04-19 16:52:18,798:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-04-19 16:52:18,799:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:805: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-04-19 16:52:18,849:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-04-19 16:52:18,850:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-04-19 16:52:18,857:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:805: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-04-19 16:52:18,885:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_d9ad40bac0f04110b7f49827a9beb7a8\9400-1451475006128-290cbb65e63a495687d9f50eefa49247.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:19,012:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_d9ad40bac0f04110b7f49827a9beb7a8\9400-1451475006128-290cbb65e63a495687d9f50eefa49247.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:19,152:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-19 16:52:19,226:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-19 16:52:19,387:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=2.821e-04, with an active set of 155 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-19 16:52:20,158:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-04-19 16:52:20,158:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-04-19 16:52:20,159:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:805: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-04-19 16:52:20,176:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-04-19 16:52:20,178:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-04-19 16:52:20,179:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:805: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-04-19 16:52:20,255:INFO:Calculating mean and std
2023-04-19 16:52:20,276:WARNING:E:\python\Anaconda3\lib\site-packages\numpy\core\_methods.py:230: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)

2023-04-19 16:52:20,282:INFO:Creating metrics dataframe
2023-04-19 16:52:20,361:INFO:Uploading results into container
2023-04-19 16:52:20,362:INFO:Uploading model into container now
2023-04-19 16:52:20,362:INFO:_master_model_container: 5
2023-04-19 16:52:20,363:INFO:_display_container: 2
2023-04-19 16:52:20,363:INFO:Lars(random_state=3117)
2023-04-19 16:52:20,364:INFO:create_model() successfully completed......................................
2023-04-19 16:52:20,491:INFO:SubProcess create_model() end ==================================
2023-04-19 16:52:20,491:INFO:Creating metrics dataframe
2023-04-19 16:52:20,513:INFO:Initializing Lasso Least Angle Regression
2023-04-19 16:52:20,514:INFO:Total runtime is 0.4987171649932861 minutes
2023-04-19 16:52:20,526:INFO:SubProcess create_model() called ==================================
2023-04-19 16:52:20,526:INFO:Initializing create_model()
2023-04-19 16:52:20,527:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000151F22FBF40>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000151F24339D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-19 16:52:20,527:INFO:Checking exceptions
2023-04-19 16:52:20,527:INFO:Importing libraries
2023-04-19 16:52:20,527:INFO:Copying training dataset
2023-04-19 16:52:20,555:INFO:Defining folds
2023-04-19 16:52:20,555:INFO:Declaring metric variables
2023-04-19 16:52:20,565:INFO:Importing untrained model
2023-04-19 16:52:20,576:INFO:Lasso Least Angle Regression Imported successfully
2023-04-19 16:52:20,595:INFO:Starting cross validation
2023-04-19 16:52:20,603:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 16:52:20,678:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_cd87c193d2aa4dae88cbd8b0ececb238\9400-1451475006128-802c4a85412d4736a4aad26410739bc4.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:20,701:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_cd87c193d2aa4dae88cbd8b0ececb238\9400-1451475006128-802c4a85412d4736a4aad26410739bc4.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:20,722:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_cd87c193d2aa4dae88cbd8b0ececb238\9400-1451475006128-802c4a85412d4736a4aad26410739bc4.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:20,752:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_cd87c193d2aa4dae88cbd8b0ececb238\9400-1451475006128-802c4a85412d4736a4aad26410739bc4.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:20,891:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-19 16:52:20,891:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-19 16:52:20,928:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-19 16:52:20,960:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-19 16:52:21,189:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_cd87c193d2aa4dae88cbd8b0ececb238\9400-1451475006128-802c4a85412d4736a4aad26410739bc4.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:21,220:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_cd87c193d2aa4dae88cbd8b0ececb238\9400-1451475006128-802c4a85412d4736a4aad26410739bc4.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:21,243:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_cd87c193d2aa4dae88cbd8b0ececb238\9400-1451475006128-802c4a85412d4736a4aad26410739bc4.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:21,455:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-19 16:52:21,488:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-19 16:52:21,534:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-19 16:52:21,705:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 16:52:21,820:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_cd87c193d2aa4dae88cbd8b0ececb238\9400-1451475006128-802c4a85412d4736a4aad26410739bc4.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:21,840:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_cd87c193d2aa4dae88cbd8b0ececb238\9400-1451475006128-802c4a85412d4736a4aad26410739bc4.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:22,038:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-19 16:52:22,068:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-19 16:52:22,250:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 16:52:22,322:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_cd87c193d2aa4dae88cbd8b0ececb238\9400-1451475006128-802c4a85412d4736a4aad26410739bc4.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:22,496:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-19 16:52:22,922:INFO:Calculating mean and std
2023-04-19 16:52:22,925:INFO:Creating metrics dataframe
2023-04-19 16:52:23,007:INFO:Uploading results into container
2023-04-19 16:52:23,008:INFO:Uploading model into container now
2023-04-19 16:52:23,009:INFO:_master_model_container: 6
2023-04-19 16:52:23,009:INFO:_display_container: 2
2023-04-19 16:52:23,010:INFO:LassoLars(random_state=3117)
2023-04-19 16:52:23,010:INFO:create_model() successfully completed......................................
2023-04-19 16:52:23,132:INFO:SubProcess create_model() end ==================================
2023-04-19 16:52:23,133:INFO:Creating metrics dataframe
2023-04-19 16:52:23,160:INFO:Initializing Orthogonal Matching Pursuit
2023-04-19 16:52:23,160:INFO:Total runtime is 0.5428163727124532 minutes
2023-04-19 16:52:23,171:INFO:SubProcess create_model() called ==================================
2023-04-19 16:52:23,172:INFO:Initializing create_model()
2023-04-19 16:52:23,172:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000151F22FBF40>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000151F24339D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-19 16:52:23,172:INFO:Checking exceptions
2023-04-19 16:52:23,173:INFO:Importing libraries
2023-04-19 16:52:23,173:INFO:Copying training dataset
2023-04-19 16:52:23,199:INFO:Defining folds
2023-04-19 16:52:23,200:INFO:Declaring metric variables
2023-04-19 16:52:23,208:INFO:Importing untrained model
2023-04-19 16:52:23,219:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-19 16:52:23,240:INFO:Starting cross validation
2023-04-19 16:52:23,246:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 16:52:23,334:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_a5fb06b5291a45e187ca35b3fbbee415\9400-1451475006128-d45f7baf159d4586b410a278caa7ac00.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:23,356:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_a5fb06b5291a45e187ca35b3fbbee415\9400-1451475006128-d45f7baf159d4586b410a278caa7ac00.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:23,377:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_a5fb06b5291a45e187ca35b3fbbee415\9400-1451475006128-d45f7baf159d4586b410a278caa7ac00.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:23,400:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_a5fb06b5291a45e187ca35b3fbbee415\9400-1451475006128-d45f7baf159d4586b410a278caa7ac00.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:23,541:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-19 16:52:23,569:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-19 16:52:23,575:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-19 16:52:23,601:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-19 16:52:23,935:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_a5fb06b5291a45e187ca35b3fbbee415\9400-1451475006128-d45f7baf159d4586b410a278caa7ac00.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:23,957:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_a5fb06b5291a45e187ca35b3fbbee415\9400-1451475006128-d45f7baf159d4586b410a278caa7ac00.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:24,201:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-19 16:52:24,212:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-19 16:52:24,575:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_a5fb06b5291a45e187ca35b3fbbee415\9400-1451475006128-d45f7baf159d4586b410a278caa7ac00.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:24,672:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_a5fb06b5291a45e187ca35b3fbbee415\9400-1451475006128-d45f7baf159d4586b410a278caa7ac00.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:24,818:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-19 16:52:24,887:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_a5fb06b5291a45e187ca35b3fbbee415\9400-1451475006128-d45f7baf159d4586b410a278caa7ac00.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:24,935:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-19 16:52:24,944:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_a5fb06b5291a45e187ca35b3fbbee415\9400-1451475006128-d45f7baf159d4586b410a278caa7ac00.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:25,122:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-19 16:52:25,193:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-19 16:52:25,868:INFO:Calculating mean and std
2023-04-19 16:52:25,871:INFO:Creating metrics dataframe
2023-04-19 16:52:25,955:INFO:Uploading results into container
2023-04-19 16:52:25,956:INFO:Uploading model into container now
2023-04-19 16:52:25,957:INFO:_master_model_container: 7
2023-04-19 16:52:25,957:INFO:_display_container: 2
2023-04-19 16:52:25,957:INFO:OrthogonalMatchingPursuit()
2023-04-19 16:52:25,957:INFO:create_model() successfully completed......................................
2023-04-19 16:52:26,086:INFO:SubProcess create_model() end ==================================
2023-04-19 16:52:26,087:INFO:Creating metrics dataframe
2023-04-19 16:52:26,114:INFO:Initializing Bayesian Ridge
2023-04-19 16:52:26,115:INFO:Total runtime is 0.5920670827229818 minutes
2023-04-19 16:52:26,124:INFO:SubProcess create_model() called ==================================
2023-04-19 16:52:26,125:INFO:Initializing create_model()
2023-04-19 16:52:26,125:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000151F22FBF40>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000151F24339D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-19 16:52:26,125:INFO:Checking exceptions
2023-04-19 16:52:26,126:INFO:Importing libraries
2023-04-19 16:52:26,126:INFO:Copying training dataset
2023-04-19 16:52:26,154:INFO:Defining folds
2023-04-19 16:52:26,154:INFO:Declaring metric variables
2023-04-19 16:52:26,161:INFO:Importing untrained model
2023-04-19 16:52:26,171:INFO:Bayesian Ridge Imported successfully
2023-04-19 16:52:26,186:INFO:Starting cross validation
2023-04-19 16:52:26,191:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 16:52:26,249:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_608bb41005764764ad92b06ded48d914\9400-1451475006128-f5929803039f4738a8a5cd350f224f29.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:26,269:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_608bb41005764764ad92b06ded48d914\9400-1451475006128-f5929803039f4738a8a5cd350f224f29.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:26,290:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_608bb41005764764ad92b06ded48d914\9400-1451475006128-f5929803039f4738a8a5cd350f224f29.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:26,316:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_608bb41005764764ad92b06ded48d914\9400-1451475006128-f5929803039f4738a8a5cd350f224f29.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:27,632:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_608bb41005764764ad92b06ded48d914\9400-1451475006128-f5929803039f4738a8a5cd350f224f29.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:27,653:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_608bb41005764764ad92b06ded48d914\9400-1451475006128-f5929803039f4738a8a5cd350f224f29.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:27,676:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_608bb41005764764ad92b06ded48d914\9400-1451475006128-f5929803039f4738a8a5cd350f224f29.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:27,701:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_608bb41005764764ad92b06ded48d914\9400-1451475006128-f5929803039f4738a8a5cd350f224f29.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:28,618:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_608bb41005764764ad92b06ded48d914\9400-1451475006128-f5929803039f4738a8a5cd350f224f29.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:28,640:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_608bb41005764764ad92b06ded48d914\9400-1451475006128-f5929803039f4738a8a5cd350f224f29.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:29,478:INFO:Calculating mean and std
2023-04-19 16:52:29,481:INFO:Creating metrics dataframe
2023-04-19 16:52:29,559:INFO:Uploading results into container
2023-04-19 16:52:29,560:INFO:Uploading model into container now
2023-04-19 16:52:29,561:INFO:_master_model_container: 8
2023-04-19 16:52:29,561:INFO:_display_container: 2
2023-04-19 16:52:29,561:INFO:BayesianRidge()
2023-04-19 16:52:29,561:INFO:create_model() successfully completed......................................
2023-04-19 16:52:29,670:INFO:SubProcess create_model() end ==================================
2023-04-19 16:52:29,670:INFO:Creating metrics dataframe
2023-04-19 16:52:29,688:INFO:Initializing Passive Aggressive Regressor
2023-04-19 16:52:29,689:INFO:Total runtime is 0.6516339302062989 minutes
2023-04-19 16:52:29,696:INFO:SubProcess create_model() called ==================================
2023-04-19 16:52:29,698:INFO:Initializing create_model()
2023-04-19 16:52:29,698:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000151F22FBF40>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000151F24339D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-19 16:52:29,698:INFO:Checking exceptions
2023-04-19 16:52:29,698:INFO:Importing libraries
2023-04-19 16:52:29,699:INFO:Copying training dataset
2023-04-19 16:52:29,719:INFO:Defining folds
2023-04-19 16:52:29,719:INFO:Declaring metric variables
2023-04-19 16:52:29,727:INFO:Importing untrained model
2023-04-19 16:52:29,735:INFO:Passive Aggressive Regressor Imported successfully
2023-04-19 16:52:29,752:INFO:Starting cross validation
2023-04-19 16:52:29,757:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 16:52:29,817:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_4b82db5746374eb3bd630b736a0447ab\9400-1451475006128-d86139595d3b4a09aa4a2df4d51810fe.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:29,831:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_4b82db5746374eb3bd630b736a0447ab\9400-1451475006128-d86139595d3b4a09aa4a2df4d51810fe.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:29,854:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_4b82db5746374eb3bd630b736a0447ab\9400-1451475006128-d86139595d3b4a09aa4a2df4d51810fe.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:29,876:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_4b82db5746374eb3bd630b736a0447ab\9400-1451475006128-d86139595d3b4a09aa4a2df4d51810fe.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:30,401:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_4b82db5746374eb3bd630b736a0447ab\9400-1451475006128-d86139595d3b4a09aa4a2df4d51810fe.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:30,421:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_4b82db5746374eb3bd630b736a0447ab\9400-1451475006128-d86139595d3b4a09aa4a2df4d51810fe.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:30,722:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_4b82db5746374eb3bd630b736a0447ab\9400-1451475006128-d86139595d3b4a09aa4a2df4d51810fe.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:30,769:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_4b82db5746374eb3bd630b736a0447ab\9400-1451475006128-d86139595d3b4a09aa4a2df4d51810fe.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:30,946:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_4b82db5746374eb3bd630b736a0447ab\9400-1451475006128-d86139595d3b4a09aa4a2df4d51810fe.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:30,967:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_4b82db5746374eb3bd630b736a0447ab\9400-1451475006128-d86139595d3b4a09aa4a2df4d51810fe.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:31,625:INFO:Calculating mean and std
2023-04-19 16:52:31,627:INFO:Creating metrics dataframe
2023-04-19 16:52:31,708:INFO:Uploading results into container
2023-04-19 16:52:31,708:INFO:Uploading model into container now
2023-04-19 16:52:31,709:INFO:_master_model_container: 9
2023-04-19 16:52:31,709:INFO:_display_container: 2
2023-04-19 16:52:31,709:INFO:PassiveAggressiveRegressor(random_state=3117)
2023-04-19 16:52:31,710:INFO:create_model() successfully completed......................................
2023-04-19 16:52:31,811:INFO:SubProcess create_model() end ==================================
2023-04-19 16:52:31,811:INFO:Creating metrics dataframe
2023-04-19 16:52:31,829:INFO:Initializing Huber Regressor
2023-04-19 16:52:31,829:INFO:Total runtime is 0.6873117089271547 minutes
2023-04-19 16:52:31,835:INFO:SubProcess create_model() called ==================================
2023-04-19 16:52:31,836:INFO:Initializing create_model()
2023-04-19 16:52:31,836:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000151F22FBF40>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000151F24339D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-19 16:52:31,837:INFO:Checking exceptions
2023-04-19 16:52:31,837:INFO:Importing libraries
2023-04-19 16:52:31,838:INFO:Copying training dataset
2023-04-19 16:52:31,858:INFO:Defining folds
2023-04-19 16:52:31,858:INFO:Declaring metric variables
2023-04-19 16:52:31,867:INFO:Importing untrained model
2023-04-19 16:52:31,874:INFO:Huber Regressor Imported successfully
2023-04-19 16:52:31,890:INFO:Starting cross validation
2023-04-19 16:52:31,897:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 16:52:31,954:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_1c79a4352591437c8888d6d6f1fe9d99\9400-1451475006128-6c9fe2cb62b5426ea8763a8cdf07f6a8.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:31,969:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_1c79a4352591437c8888d6d6f1fe9d99\9400-1451475006128-6c9fe2cb62b5426ea8763a8cdf07f6a8.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:31,985:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_1c79a4352591437c8888d6d6f1fe9d99\9400-1451475006128-6c9fe2cb62b5426ea8763a8cdf07f6a8.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:32,005:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_1c79a4352591437c8888d6d6f1fe9d99\9400-1451475006128-6c9fe2cb62b5426ea8763a8cdf07f6a8.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:33,630:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-19 16:52:33,631:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-19 16:52:33,631:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-19 16:52:34,135:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_1c79a4352591437c8888d6d6f1fe9d99\9400-1451475006128-6c9fe2cb62b5426ea8763a8cdf07f6a8.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:34,159:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_1c79a4352591437c8888d6d6f1fe9d99\9400-1451475006128-6c9fe2cb62b5426ea8763a8cdf07f6a8.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:34,185:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_1c79a4352591437c8888d6d6f1fe9d99\9400-1451475006128-6c9fe2cb62b5426ea8763a8cdf07f6a8.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:34,210:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_1c79a4352591437c8888d6d6f1fe9d99\9400-1451475006128-6c9fe2cb62b5426ea8763a8cdf07f6a8.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:36,018:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-19 16:52:36,033:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-19 16:52:36,104:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-19 16:52:36,159:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-19 16:52:36,720:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_1c79a4352591437c8888d6d6f1fe9d99\9400-1451475006128-6c9fe2cb62b5426ea8763a8cdf07f6a8.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:36,724:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_1c79a4352591437c8888d6d6f1fe9d99\9400-1451475006128-6c9fe2cb62b5426ea8763a8cdf07f6a8.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:37,070:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 16:52:38,247:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-19 16:52:38,445:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-19 16:52:38,967:INFO:Calculating mean and std
2023-04-19 16:52:38,971:INFO:Creating metrics dataframe
2023-04-19 16:52:39,099:INFO:Uploading results into container
2023-04-19 16:52:39,101:INFO:Uploading model into container now
2023-04-19 16:52:39,102:INFO:_master_model_container: 10
2023-04-19 16:52:39,102:INFO:_display_container: 2
2023-04-19 16:52:39,103:INFO:HuberRegressor()
2023-04-19 16:52:39,103:INFO:create_model() successfully completed......................................
2023-04-19 16:52:39,234:INFO:SubProcess create_model() end ==================================
2023-04-19 16:52:39,234:INFO:Creating metrics dataframe
2023-04-19 16:52:39,258:INFO:Initializing K Neighbors Regressor
2023-04-19 16:52:39,258:INFO:Total runtime is 0.811116663614909 minutes
2023-04-19 16:52:39,271:INFO:SubProcess create_model() called ==================================
2023-04-19 16:52:39,272:INFO:Initializing create_model()
2023-04-19 16:52:39,272:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000151F22FBF40>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000151F24339D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-19 16:52:39,273:INFO:Checking exceptions
2023-04-19 16:52:39,273:INFO:Importing libraries
2023-04-19 16:52:39,273:INFO:Copying training dataset
2023-04-19 16:52:39,300:INFO:Defining folds
2023-04-19 16:52:39,300:INFO:Declaring metric variables
2023-04-19 16:52:39,308:INFO:Importing untrained model
2023-04-19 16:52:39,320:INFO:K Neighbors Regressor Imported successfully
2023-04-19 16:52:39,338:INFO:Starting cross validation
2023-04-19 16:52:39,342:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 16:52:39,409:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_48a92fd1347f40f9aa8809ffb4baa023\9400-1451475006128-4a0817691a814549aa77e07628c4319b.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:39,430:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_48a92fd1347f40f9aa8809ffb4baa023\9400-1451475006128-4a0817691a814549aa77e07628c4319b.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:39,451:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_48a92fd1347f40f9aa8809ffb4baa023\9400-1451475006128-4a0817691a814549aa77e07628c4319b.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:39,472:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_48a92fd1347f40f9aa8809ffb4baa023\9400-1451475006128-4a0817691a814549aa77e07628c4319b.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:40,172:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_48a92fd1347f40f9aa8809ffb4baa023\9400-1451475006128-4a0817691a814549aa77e07628c4319b.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:40,186:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_48a92fd1347f40f9aa8809ffb4baa023\9400-1451475006128-4a0817691a814549aa77e07628c4319b.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:40,206:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_48a92fd1347f40f9aa8809ffb4baa023\9400-1451475006128-4a0817691a814549aa77e07628c4319b.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:40,377:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 16:52:40,829:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_48a92fd1347f40f9aa8809ffb4baa023\9400-1451475006128-4a0817691a814549aa77e07628c4319b.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:40,858:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_48a92fd1347f40f9aa8809ffb4baa023\9400-1451475006128-4a0817691a814549aa77e07628c4319b.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:40,938:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_48a92fd1347f40f9aa8809ffb4baa023\9400-1451475006128-4a0817691a814549aa77e07628c4319b.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:41,687:INFO:Calculating mean and std
2023-04-19 16:52:41,695:INFO:Creating metrics dataframe
2023-04-19 16:52:41,834:INFO:Uploading results into container
2023-04-19 16:52:41,836:INFO:Uploading model into container now
2023-04-19 16:52:41,836:INFO:_master_model_container: 11
2023-04-19 16:52:41,836:INFO:_display_container: 2
2023-04-19 16:52:41,837:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-19 16:52:41,838:INFO:create_model() successfully completed......................................
2023-04-19 16:52:41,971:INFO:SubProcess create_model() end ==================================
2023-04-19 16:52:41,971:INFO:Creating metrics dataframe
2023-04-19 16:52:42,001:INFO:Initializing Decision Tree Regressor
2023-04-19 16:52:42,001:INFO:Total runtime is 0.8568384925524395 minutes
2023-04-19 16:52:42,011:INFO:SubProcess create_model() called ==================================
2023-04-19 16:52:42,012:INFO:Initializing create_model()
2023-04-19 16:52:42,013:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000151F22FBF40>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000151F24339D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-19 16:52:42,014:INFO:Checking exceptions
2023-04-19 16:52:42,014:INFO:Importing libraries
2023-04-19 16:52:42,014:INFO:Copying training dataset
2023-04-19 16:52:42,041:INFO:Defining folds
2023-04-19 16:52:42,041:INFO:Declaring metric variables
2023-04-19 16:52:42,052:INFO:Importing untrained model
2023-04-19 16:52:42,064:INFO:Decision Tree Regressor Imported successfully
2023-04-19 16:52:42,084:INFO:Starting cross validation
2023-04-19 16:52:42,089:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 16:52:42,173:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_ba285b5d760f4d019796ae4a0072ab92\9400-1451475006128-5df027444c9c456c837e7ecb6eee2e90.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:42,200:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_ba285b5d760f4d019796ae4a0072ab92\9400-1451475006128-5df027444c9c456c837e7ecb6eee2e90.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:42,222:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_ba285b5d760f4d019796ae4a0072ab92\9400-1451475006128-5df027444c9c456c837e7ecb6eee2e90.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:42,243:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_ba285b5d760f4d019796ae4a0072ab92\9400-1451475006128-5df027444c9c456c837e7ecb6eee2e90.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:43,853:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_ba285b5d760f4d019796ae4a0072ab92\9400-1451475006128-5df027444c9c456c837e7ecb6eee2e90.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:43,873:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_ba285b5d760f4d019796ae4a0072ab92\9400-1451475006128-5df027444c9c456c837e7ecb6eee2e90.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:43,915:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_ba285b5d760f4d019796ae4a0072ab92\9400-1451475006128-5df027444c9c456c837e7ecb6eee2e90.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:43,996:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_ba285b5d760f4d019796ae4a0072ab92\9400-1451475006128-5df027444c9c456c837e7ecb6eee2e90.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:44,993:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_ba285b5d760f4d019796ae4a0072ab92\9400-1451475006128-5df027444c9c456c837e7ecb6eee2e90.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:45,015:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_ba285b5d760f4d019796ae4a0072ab92\9400-1451475006128-5df027444c9c456c837e7ecb6eee2e90.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:45,830:INFO:Calculating mean and std
2023-04-19 16:52:45,834:INFO:Creating metrics dataframe
2023-04-19 16:52:46,032:INFO:Uploading results into container
2023-04-19 16:52:46,033:INFO:Uploading model into container now
2023-04-19 16:52:46,034:INFO:_master_model_container: 12
2023-04-19 16:52:46,035:INFO:_display_container: 2
2023-04-19 16:52:46,035:INFO:DecisionTreeRegressor(random_state=3117)
2023-04-19 16:52:46,035:INFO:create_model() successfully completed......................................
2023-04-19 16:52:46,140:INFO:SubProcess create_model() end ==================================
2023-04-19 16:52:46,140:INFO:Creating metrics dataframe
2023-04-19 16:52:46,160:INFO:Initializing Random Forest Regressor
2023-04-19 16:52:46,160:INFO:Total runtime is 0.9261486848195395 minutes
2023-04-19 16:52:46,167:INFO:SubProcess create_model() called ==================================
2023-04-19 16:52:46,168:INFO:Initializing create_model()
2023-04-19 16:52:46,169:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000151F22FBF40>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000151F24339D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-19 16:52:46,169:INFO:Checking exceptions
2023-04-19 16:52:46,169:INFO:Importing libraries
2023-04-19 16:52:46,170:INFO:Copying training dataset
2023-04-19 16:52:46,190:INFO:Defining folds
2023-04-19 16:52:46,190:INFO:Declaring metric variables
2023-04-19 16:52:46,199:INFO:Importing untrained model
2023-04-19 16:52:46,207:INFO:Random Forest Regressor Imported successfully
2023-04-19 16:52:46,222:INFO:Starting cross validation
2023-04-19 16:52:46,230:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 16:52:46,303:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_dfdbf3b8aa374537a40d2c091ed782f4\9400-1451475006128-dc72d5ed708f448baffbc29a2a8fff18.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:46,317:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_dfdbf3b8aa374537a40d2c091ed782f4\9400-1451475006128-dc72d5ed708f448baffbc29a2a8fff18.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:46,335:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_dfdbf3b8aa374537a40d2c091ed782f4\9400-1451475006128-dc72d5ed708f448baffbc29a2a8fff18.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:46,355:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_dfdbf3b8aa374537a40d2c091ed782f4\9400-1451475006128-dc72d5ed708f448baffbc29a2a8fff18.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:52,094:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 16:52:52,462:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 16:52:52,533:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 16:52:52,535:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 16:52:53,078:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_dfdbf3b8aa374537a40d2c091ed782f4\9400-1451475006128-dc72d5ed708f448baffbc29a2a8fff18.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:53,097:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_dfdbf3b8aa374537a40d2c091ed782f4\9400-1451475006128-dc72d5ed708f448baffbc29a2a8fff18.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:53,139:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 16:52:53,185:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_dfdbf3b8aa374537a40d2c091ed782f4\9400-1451475006128-dc72d5ed708f448baffbc29a2a8fff18.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:54,034:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_dfdbf3b8aa374537a40d2c091ed782f4\9400-1451475006128-dc72d5ed708f448baffbc29a2a8fff18.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:52:58,658:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 16:52:58,766:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 16:52:59,688:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 16:52:59,894:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 16:52:59,980:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 16:53:00,276:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_dfdbf3b8aa374537a40d2c091ed782f4\9400-1451475006128-dc72d5ed708f448baffbc29a2a8fff18.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:00,355:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 16:53:00,365:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_dfdbf3b8aa374537a40d2c091ed782f4\9400-1451475006128-dc72d5ed708f448baffbc29a2a8fff18.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:04,746:INFO:Calculating mean and std
2023-04-19 16:53:04,752:INFO:Creating metrics dataframe
2023-04-19 16:53:04,951:INFO:Uploading results into container
2023-04-19 16:53:04,952:INFO:Uploading model into container now
2023-04-19 16:53:04,953:INFO:_master_model_container: 13
2023-04-19 16:53:04,953:INFO:_display_container: 2
2023-04-19 16:53:04,956:INFO:RandomForestRegressor(n_jobs=-1, random_state=3117)
2023-04-19 16:53:04,956:INFO:create_model() successfully completed......................................
2023-04-19 16:53:05,068:INFO:SubProcess create_model() end ==================================
2023-04-19 16:53:05,069:INFO:Creating metrics dataframe
2023-04-19 16:53:05,092:INFO:Initializing Extra Trees Regressor
2023-04-19 16:53:05,092:INFO:Total runtime is 1.2416834076245626 minutes
2023-04-19 16:53:05,097:INFO:SubProcess create_model() called ==================================
2023-04-19 16:53:05,098:INFO:Initializing create_model()
2023-04-19 16:53:05,098:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000151F22FBF40>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000151F24339D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-19 16:53:05,099:INFO:Checking exceptions
2023-04-19 16:53:05,099:INFO:Importing libraries
2023-04-19 16:53:05,099:INFO:Copying training dataset
2023-04-19 16:53:05,124:INFO:Defining folds
2023-04-19 16:53:05,124:INFO:Declaring metric variables
2023-04-19 16:53:05,131:INFO:Importing untrained model
2023-04-19 16:53:05,143:INFO:Extra Trees Regressor Imported successfully
2023-04-19 16:53:05,159:INFO:Starting cross validation
2023-04-19 16:53:05,164:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 16:53:05,232:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_2cca597992a447b58c067d9ed1038c6e\9400-1451475006128-2d24962dfd7b4316a629bc11df766c6e.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:05,251:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_2cca597992a447b58c067d9ed1038c6e\9400-1451475006128-2d24962dfd7b4316a629bc11df766c6e.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:05,273:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_2cca597992a447b58c067d9ed1038c6e\9400-1451475006128-2d24962dfd7b4316a629bc11df766c6e.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:05,296:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_2cca597992a447b58c067d9ed1038c6e\9400-1451475006128-2d24962dfd7b4316a629bc11df766c6e.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:11,461:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 16:53:12,354:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_2cca597992a447b58c067d9ed1038c6e\9400-1451475006128-2d24962dfd7b4316a629bc11df766c6e.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:12,617:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_2cca597992a447b58c067d9ed1038c6e\9400-1451475006128-2d24962dfd7b4316a629bc11df766c6e.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:12,776:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 16:53:12,794:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 16:53:13,360:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_2cca597992a447b58c067d9ed1038c6e\9400-1451475006128-2d24962dfd7b4316a629bc11df766c6e.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:13,899:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_2cca597992a447b58c067d9ed1038c6e\9400-1451475006128-2d24962dfd7b4316a629bc11df766c6e.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:17,671:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 16:53:19,028:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 16:53:19,394:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 16:53:19,998:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 16:53:20,168:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_2cca597992a447b58c067d9ed1038c6e\9400-1451475006128-2d24962dfd7b4316a629bc11df766c6e.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:20,179:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 16:53:20,493:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 16:53:20,654:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_2cca597992a447b58c067d9ed1038c6e\9400-1451475006128-2d24962dfd7b4316a629bc11df766c6e.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:21,723:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 16:53:24,332:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 16:53:25,359:INFO:Calculating mean and std
2023-04-19 16:53:25,364:INFO:Creating metrics dataframe
2023-04-19 16:53:25,599:INFO:Uploading results into container
2023-04-19 16:53:25,602:INFO:Uploading model into container now
2023-04-19 16:53:25,603:INFO:_master_model_container: 14
2023-04-19 16:53:25,603:INFO:_display_container: 2
2023-04-19 16:53:25,604:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=3117)
2023-04-19 16:53:25,604:INFO:create_model() successfully completed......................................
2023-04-19 16:53:25,735:INFO:SubProcess create_model() end ==================================
2023-04-19 16:53:25,735:INFO:Creating metrics dataframe
2023-04-19 16:53:25,764:INFO:Initializing AdaBoost Regressor
2023-04-19 16:53:25,764:INFO:Total runtime is 1.5862226247787476 minutes
2023-04-19 16:53:25,775:INFO:SubProcess create_model() called ==================================
2023-04-19 16:53:25,776:INFO:Initializing create_model()
2023-04-19 16:53:25,777:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000151F22FBF40>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000151F24339D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-19 16:53:25,777:INFO:Checking exceptions
2023-04-19 16:53:25,778:INFO:Importing libraries
2023-04-19 16:53:25,778:INFO:Copying training dataset
2023-04-19 16:53:25,809:INFO:Defining folds
2023-04-19 16:53:25,810:INFO:Declaring metric variables
2023-04-19 16:53:25,819:INFO:Importing untrained model
2023-04-19 16:53:25,828:INFO:AdaBoost Regressor Imported successfully
2023-04-19 16:53:25,846:INFO:Starting cross validation
2023-04-19 16:53:25,850:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 16:53:25,909:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_14c8f16a8f5b48a087b96cec425d1c0f\9400-1451475006128-0debc0938d7f4aaea608baed186e366d.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:25,928:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_14c8f16a8f5b48a087b96cec425d1c0f\9400-1451475006128-0debc0938d7f4aaea608baed186e366d.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:25,950:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_14c8f16a8f5b48a087b96cec425d1c0f\9400-1451475006128-0debc0938d7f4aaea608baed186e366d.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:25,974:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_14c8f16a8f5b48a087b96cec425d1c0f\9400-1451475006128-0debc0938d7f4aaea608baed186e366d.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:28,856:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_14c8f16a8f5b48a087b96cec425d1c0f\9400-1451475006128-0debc0938d7f4aaea608baed186e366d.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:28,887:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_14c8f16a8f5b48a087b96cec425d1c0f\9400-1451475006128-0debc0938d7f4aaea608baed186e366d.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:28,907:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_14c8f16a8f5b48a087b96cec425d1c0f\9400-1451475006128-0debc0938d7f4aaea608baed186e366d.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:29,115:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_14c8f16a8f5b48a087b96cec425d1c0f\9400-1451475006128-0debc0938d7f4aaea608baed186e366d.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:32,026:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_14c8f16a8f5b48a087b96cec425d1c0f\9400-1451475006128-0debc0938d7f4aaea608baed186e366d.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:32,091:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_14c8f16a8f5b48a087b96cec425d1c0f\9400-1451475006128-0debc0938d7f4aaea608baed186e366d.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:33,870:INFO:Calculating mean and std
2023-04-19 16:53:33,873:INFO:Creating metrics dataframe
2023-04-19 16:53:34,035:INFO:Uploading results into container
2023-04-19 16:53:34,039:INFO:Uploading model into container now
2023-04-19 16:53:34,040:INFO:_master_model_container: 15
2023-04-19 16:53:34,040:INFO:_display_container: 2
2023-04-19 16:53:34,041:INFO:AdaBoostRegressor(random_state=3117)
2023-04-19 16:53:34,041:INFO:create_model() successfully completed......................................
2023-04-19 16:53:34,145:INFO:SubProcess create_model() end ==================================
2023-04-19 16:53:34,145:INFO:Creating metrics dataframe
2023-04-19 16:53:34,165:INFO:Initializing Gradient Boosting Regressor
2023-04-19 16:53:34,166:INFO:Total runtime is 1.7262548883756001 minutes
2023-04-19 16:53:34,173:INFO:SubProcess create_model() called ==================================
2023-04-19 16:53:34,174:INFO:Initializing create_model()
2023-04-19 16:53:34,174:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000151F22FBF40>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000151F24339D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-19 16:53:34,174:INFO:Checking exceptions
2023-04-19 16:53:34,175:INFO:Importing libraries
2023-04-19 16:53:34,175:INFO:Copying training dataset
2023-04-19 16:53:34,194:INFO:Defining folds
2023-04-19 16:53:34,195:INFO:Declaring metric variables
2023-04-19 16:53:34,202:INFO:Importing untrained model
2023-04-19 16:53:34,210:INFO:Gradient Boosting Regressor Imported successfully
2023-04-19 16:53:34,224:INFO:Starting cross validation
2023-04-19 16:53:34,228:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 16:53:34,281:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_9a60359127b843eda2f8f61f105abcc5\9400-1451475006128-bc9c580208294098862337e9cd4f08cd.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:34,295:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_9a60359127b843eda2f8f61f105abcc5\9400-1451475006128-bc9c580208294098862337e9cd4f08cd.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:34,313:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_9a60359127b843eda2f8f61f105abcc5\9400-1451475006128-bc9c580208294098862337e9cd4f08cd.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:34,336:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_9a60359127b843eda2f8f61f105abcc5\9400-1451475006128-bc9c580208294098862337e9cd4f08cd.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:36,910:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_9a60359127b843eda2f8f61f105abcc5\9400-1451475006128-bc9c580208294098862337e9cd4f08cd.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:36,957:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_9a60359127b843eda2f8f61f105abcc5\9400-1451475006128-bc9c580208294098862337e9cd4f08cd.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:36,978:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_9a60359127b843eda2f8f61f105abcc5\9400-1451475006128-bc9c580208294098862337e9cd4f08cd.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:37,000:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_9a60359127b843eda2f8f61f105abcc5\9400-1451475006128-bc9c580208294098862337e9cd4f08cd.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:39,382:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 16:53:39,404:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 16:53:39,446:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 16:53:39,505:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-19 16:53:40,145:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_9a60359127b843eda2f8f61f105abcc5\9400-1451475006128-bc9c580208294098862337e9cd4f08cd.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:40,303:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_9a60359127b843eda2f8f61f105abcc5\9400-1451475006128-bc9c580208294098862337e9cd4f08cd.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:40,460:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 16:53:40,596:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-19 16:53:42,856:INFO:Calculating mean and std
2023-04-19 16:53:42,860:INFO:Creating metrics dataframe
2023-04-19 16:53:43,112:INFO:Uploading results into container
2023-04-19 16:53:43,115:INFO:Uploading model into container now
2023-04-19 16:53:43,122:INFO:_master_model_container: 16
2023-04-19 16:53:43,122:INFO:_display_container: 2
2023-04-19 16:53:43,123:INFO:GradientBoostingRegressor(random_state=3117)
2023-04-19 16:53:43,124:INFO:create_model() successfully completed......................................
2023-04-19 16:53:43,250:INFO:SubProcess create_model() end ==================================
2023-04-19 16:53:43,251:INFO:Creating metrics dataframe
2023-04-19 16:53:43,282:INFO:Initializing Light Gradient Boosting Machine
2023-04-19 16:53:43,282:INFO:Total runtime is 1.8781967997550963 minutes
2023-04-19 16:53:43,292:INFO:SubProcess create_model() called ==================================
2023-04-19 16:53:43,293:INFO:Initializing create_model()
2023-04-19 16:53:43,294:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000151F22FBF40>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000151F24339D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-19 16:53:43,294:INFO:Checking exceptions
2023-04-19 16:53:43,295:INFO:Importing libraries
2023-04-19 16:53:43,295:INFO:Copying training dataset
2023-04-19 16:53:43,324:INFO:Defining folds
2023-04-19 16:53:43,324:INFO:Declaring metric variables
2023-04-19 16:53:43,336:INFO:Importing untrained model
2023-04-19 16:53:43,345:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-19 16:53:43,367:INFO:Starting cross validation
2023-04-19 16:53:43,373:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 16:53:46,390:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_669ed150db3940e6ba391bcd16a338bd\9400-1451475006128-50af96cb72484de9b17f8544da0b4026.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:46,410:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_669ed150db3940e6ba391bcd16a338bd\9400-1451475006128-50af96cb72484de9b17f8544da0b4026.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:46,420:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_669ed150db3940e6ba391bcd16a338bd\9400-1451475006128-50af96cb72484de9b17f8544da0b4026.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:46,466:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_669ed150db3940e6ba391bcd16a338bd\9400-1451475006128-50af96cb72484de9b17f8544da0b4026.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:47,972:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_669ed150db3940e6ba391bcd16a338bd\9400-1451475006128-50af96cb72484de9b17f8544da0b4026.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:47,982:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_669ed150db3940e6ba391bcd16a338bd\9400-1451475006128-50af96cb72484de9b17f8544da0b4026.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:48,023:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_669ed150db3940e6ba391bcd16a338bd\9400-1451475006128-50af96cb72484de9b17f8544da0b4026.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:48,085:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_669ed150db3940e6ba391bcd16a338bd\9400-1451475006128-50af96cb72484de9b17f8544da0b4026.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:49,749:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_669ed150db3940e6ba391bcd16a338bd\9400-1451475006128-50af96cb72484de9b17f8544da0b4026.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:49,769:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_669ed150db3940e6ba391bcd16a338bd\9400-1451475006128-50af96cb72484de9b17f8544da0b4026.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:51,227:INFO:Calculating mean and std
2023-04-19 16:53:51,230:INFO:Creating metrics dataframe
2023-04-19 16:53:51,436:INFO:Uploading results into container
2023-04-19 16:53:51,437:INFO:Uploading model into container now
2023-04-19 16:53:51,438:INFO:_master_model_container: 17
2023-04-19 16:53:51,438:INFO:_display_container: 2
2023-04-19 16:53:51,439:INFO:LGBMRegressor(random_state=3117)
2023-04-19 16:53:51,439:INFO:create_model() successfully completed......................................
2023-04-19 16:53:51,547:INFO:SubProcess create_model() end ==================================
2023-04-19 16:53:51,547:INFO:Creating metrics dataframe
2023-04-19 16:53:51,568:INFO:Initializing Dummy Regressor
2023-04-19 16:53:51,568:INFO:Total runtime is 2.016285757223765 minutes
2023-04-19 16:53:51,576:INFO:SubProcess create_model() called ==================================
2023-04-19 16:53:51,577:INFO:Initializing create_model()
2023-04-19 16:53:51,577:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000151F22FBF40>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000151F24339D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-19 16:53:51,577:INFO:Checking exceptions
2023-04-19 16:53:51,578:INFO:Importing libraries
2023-04-19 16:53:51,578:INFO:Copying training dataset
2023-04-19 16:53:51,601:INFO:Defining folds
2023-04-19 16:53:51,602:INFO:Declaring metric variables
2023-04-19 16:53:51,608:INFO:Importing untrained model
2023-04-19 16:53:51,618:INFO:Dummy Regressor Imported successfully
2023-04-19 16:53:51,634:INFO:Starting cross validation
2023-04-19 16:53:51,639:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-19 16:53:51,702:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_7703e317c86b415fa9deaf2c4527eb26\9400-1451475006128-ae064f8feb7b4444801fa8467f83bda3.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:51,715:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_7703e317c86b415fa9deaf2c4527eb26\9400-1451475006128-ae064f8feb7b4444801fa8467f83bda3.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:51,738:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_7703e317c86b415fa9deaf2c4527eb26\9400-1451475006128-ae064f8feb7b4444801fa8467f83bda3.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:51,757:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_7703e317c86b415fa9deaf2c4527eb26\9400-1451475006128-ae064f8feb7b4444801fa8467f83bda3.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:52,368:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_7703e317c86b415fa9deaf2c4527eb26\9400-1451475006128-ae064f8feb7b4444801fa8467f83bda3.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:52,387:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_7703e317c86b415fa9deaf2c4527eb26\9400-1451475006128-ae064f8feb7b4444801fa8467f83bda3.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:52,468:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_7703e317c86b415fa9deaf2c4527eb26\9400-1451475006128-ae064f8feb7b4444801fa8467f83bda3.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:52,899:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_7703e317c86b415fa9deaf2c4527eb26\9400-1451475006128-ae064f8feb7b4444801fa8467f83bda3.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:53,083:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_7703e317c86b415fa9deaf2c4527eb26\9400-1451475006128-ae064f8feb7b4444801fa8467f83bda3.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:53,155:WARNING:E:\python\Anaconda3\lib\site-packages\joblib\numpy_pickle.py:230: UserWarning: The memmapped array [[ 0.6075682   1.1419535   0.02332266 ... -0.29508358  0.5360768
   0.34932545]
 [-0.43520978  0.6941824  -0.00702999 ... -0.11535901  1.2159609
   0.86685675]
 [-0.06318454  1.3555514  -1.4819204  ... -0.06318454 -0.06318454
   1.3555514 ]
 ...
 [-0.12653513 -0.12653513 -0.12653513 ... -0.12653513 -0.12653513
  -0.12653513]
 [ 0.46393675  0.46393675  0.46393675 ...  0.46393675  0.46393675
   0.46393675]
 [-0.30269298 -0.30269298 -0.30269298 ... -0.30269298 -0.30269298
  -0.30269298]] loaded from the file C:\Users\ADMINI~1\AppData\Local\Temp\joblib_memmapping_folder_9400_9df93aa4d8d94b92b3f51906cd2df432_7703e317c86b415fa9deaf2c4527eb26\9400-1451475006128-ae064f8feb7b4444801fa8467f83bda3.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details
  warnings.warn(message)

2023-04-19 16:53:54,464:INFO:Calculating mean and std
2023-04-19 16:53:54,467:INFO:Creating metrics dataframe
2023-04-19 16:53:54,666:INFO:Uploading results into container
2023-04-19 16:53:54,667:INFO:Uploading model into container now
2023-04-19 16:53:54,668:INFO:_master_model_container: 18
2023-04-19 16:53:54,668:INFO:_display_container: 2
2023-04-19 16:53:54,669:INFO:DummyRegressor()
2023-04-19 16:53:54,669:INFO:create_model() successfully completed......................................
2023-04-19 16:53:54,771:INFO:SubProcess create_model() end ==================================
2023-04-19 16:53:54,771:INFO:Creating metrics dataframe
2023-04-19 16:53:54,810:INFO:Initializing create_model()
2023-04-19 16:53:54,812:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000151F22FBF40>, estimator=OrthogonalMatchingPursuit(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-19 16:53:54,813:INFO:Checking exceptions
2023-04-19 16:53:54,817:INFO:Importing libraries
2023-04-19 16:53:54,818:INFO:Copying training dataset
2023-04-19 16:53:54,838:INFO:Defining folds
2023-04-19 16:53:54,838:INFO:Declaring metric variables
2023-04-19 16:53:54,838:INFO:Importing untrained model
2023-04-19 16:53:54,838:INFO:Declaring custom model
2023-04-19 16:53:54,839:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-19 16:53:54,842:INFO:Cross validation set to False
2023-04-19 16:53:54,842:INFO:Fitting Model
2023-04-19 16:53:54,930:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-19 16:53:55,543:INFO:OrthogonalMatchingPursuit()
2023-04-19 16:53:55,543:INFO:create_model() successfully completed......................................
2023-04-19 16:53:55,743:INFO:_master_model_container: 18
2023-04-19 16:53:55,745:INFO:_display_container: 2
2023-04-19 16:53:55,746:INFO:OrthogonalMatchingPursuit()
2023-04-19 16:53:55,747:INFO:compare_models() successfully completed......................................
2023-04-24 09:34:40,976:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 09:34:40,977:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 09:34:40,977:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 09:34:40,977:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 09:34:56,858:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-24 09:35:04,653:WARNING:E:\python\Anaconda3\lib\site-packages\seaborn\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).
  warnings.warn(msg, FutureWarning)

2023-04-24 09:35:05,020:WARNING:E:\python\Anaconda3\lib\site-packages\seaborn\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).
  warnings.warn(msg, FutureWarning)

2023-04-24 09:35:10,681:INFO:PyCaret RegressionExperiment
2023-04-24 09:35:10,682:INFO:Logging name: reg-default-name
2023-04-24 09:35:10,682:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-24 09:35:10,683:INFO:version 3.0.0
2023-04-24 09:35:10,683:INFO:Initializing setup()
2023-04-24 09:35:10,683:INFO:self.USI: 7531
2023-04-24 09:35:10,683:INFO:self._variable_keys: {'log_plots_param', 'USI', 'exp_name_log', 'fold_generator', 'logging_param', 'gpu_param', 'y_test', 'pipeline', 'idx', 'X_test', 'data', 'y_train', 'gpu_n_jobs_param', 'fold_shuffle_param', 'transform_target_param', 'memory', 'y', '_ml_usecase', 'X', 'n_jobs_param', 'X_train', 'target_param', 'html_param', 'exp_id', '_available_plots', 'fold_groups_param', 'seed'}
2023-04-24 09:35:10,683:INFO:Checking environment
2023-04-24 09:35:10,683:INFO:python_version: 3.9.13
2023-04-24 09:35:10,683:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-04-24 09:35:10,684:INFO:machine: AMD64
2023-04-24 09:35:10,684:INFO:platform: Windows-10-10.0.18363-SP0
2023-04-24 09:35:10,684:INFO:Memory: svmem(total=8488050688, available=2273398784, percent=73.2, used=6214651904, free=2273398784)
2023-04-24 09:35:10,684:INFO:Physical Core: 2
2023-04-24 09:35:10,684:INFO:Logical Core: 4
2023-04-24 09:35:10,685:INFO:Checking libraries
2023-04-24 09:35:10,685:INFO:System:
2023-04-24 09:35:10,685:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-04-24 09:35:10,685:INFO:executable: E:\python\Anaconda3\python.exe
2023-04-24 09:35:10,685:INFO:   machine: Windows-10-10.0.18363-SP0
2023-04-24 09:35:10,686:INFO:PyCaret required dependencies:
2023-04-24 09:35:10,686:INFO:                 pip: 22.2.2
2023-04-24 09:35:10,686:INFO:          setuptools: 63.4.1
2023-04-24 09:35:10,686:INFO:             pycaret: 3.0.0
2023-04-24 09:35:10,686:INFO:             IPython: 7.31.1
2023-04-24 09:35:10,687:INFO:          ipywidgets: 7.6.5
2023-04-24 09:35:10,687:INFO:                tqdm: 4.64.1
2023-04-24 09:35:10,687:INFO:               numpy: 1.21.5
2023-04-24 09:35:10,687:INFO:              pandas: 1.4.4
2023-04-24 09:35:10,688:INFO:              jinja2: 2.11.3
2023-04-24 09:35:10,688:INFO:               scipy: 1.9.1
2023-04-24 09:35:10,688:INFO:              joblib: 1.2.0
2023-04-24 09:35:10,688:INFO:             sklearn: 1.0.2
2023-04-24 09:35:10,688:INFO:                pyod: 1.0.9
2023-04-24 09:35:10,688:INFO:            imblearn: 0.10.1
2023-04-24 09:35:10,689:INFO:   category_encoders: 2.6.0
2023-04-24 09:35:10,689:INFO:            lightgbm: 3.3.5
2023-04-24 09:35:10,689:INFO:               numba: 0.55.1
2023-04-24 09:35:10,689:INFO:            requests: 2.28.1
2023-04-24 09:35:10,689:INFO:          matplotlib: 3.5.2
2023-04-24 09:35:10,689:INFO:          scikitplot: 0.3.7
2023-04-24 09:35:10,690:INFO:         yellowbrick: 1.5
2023-04-24 09:35:10,690:INFO:              plotly: 5.9.0
2023-04-24 09:35:10,690:INFO:             kaleido: 0.2.1
2023-04-24 09:35:10,691:INFO:         statsmodels: 0.13.2
2023-04-24 09:35:10,691:INFO:              sktime: 0.17.1
2023-04-24 09:35:10,691:INFO:               tbats: 1.1.3
2023-04-24 09:35:10,692:INFO:            pmdarima: 2.0.3
2023-04-24 09:35:10,692:INFO:              psutil: 5.9.0
2023-04-24 09:35:10,692:INFO:PyCaret optional dependencies:
2023-04-24 09:35:10,777:INFO:                shap: Not installed
2023-04-24 09:35:10,777:INFO:           interpret: Not installed
2023-04-24 09:35:10,777:INFO:                umap: Not installed
2023-04-24 09:35:10,777:INFO:    pandas_profiling: Not installed
2023-04-24 09:35:10,777:INFO:  explainerdashboard: Not installed
2023-04-24 09:35:10,777:INFO:             autoviz: Not installed
2023-04-24 09:35:10,778:INFO:           fairlearn: Not installed
2023-04-24 09:35:10,778:INFO:             xgboost: 1.7.5
2023-04-24 09:35:10,778:INFO:            catboost: 1.1.1
2023-04-24 09:35:10,778:INFO:              kmodes: Not installed
2023-04-24 09:35:10,778:INFO:             mlxtend: Not installed
2023-04-24 09:35:10,778:INFO:       statsforecast: Not installed
2023-04-24 09:35:10,778:INFO:        tune_sklearn: Not installed
2023-04-24 09:35:10,779:INFO:                 ray: Not installed
2023-04-24 09:35:10,779:INFO:            hyperopt: Not installed
2023-04-24 09:35:10,779:INFO:              optuna: Not installed
2023-04-24 09:35:10,779:INFO:               skopt: Not installed
2023-04-24 09:35:10,779:INFO:              mlflow: Not installed
2023-04-24 09:35:10,779:INFO:              gradio: Not installed
2023-04-24 09:35:10,779:INFO:             fastapi: Not installed
2023-04-24 09:35:10,780:INFO:             uvicorn: Not installed
2023-04-24 09:35:10,780:INFO:              m2cgen: Not installed
2023-04-24 09:35:10,780:INFO:           evidently: Not installed
2023-04-24 09:35:10,780:INFO:               fugue: Not installed
2023-04-24 09:35:10,780:INFO:           streamlit: Not installed
2023-04-24 09:35:10,780:INFO:             prophet: Not installed
2023-04-24 09:35:10,780:INFO:None
2023-04-24 09:35:10,781:INFO:Set up data.
2023-04-24 09:35:11,074:INFO:Set up train/test split.
2023-04-24 09:35:11,181:INFO:Set up index.
2023-04-24 09:35:11,182:INFO:Set up folding strategy.
2023-04-24 09:35:11,182:INFO:Assigning column types.
2023-04-24 09:35:11,201:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-24 09:35:11,202:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-24 09:35:11,214:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 09:35:11,222:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 09:35:11,401:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 09:35:11,620:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 09:35:11,623:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 09:35:12,292:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-24 09:35:13,494:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-24 09:35:13,502:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 09:35:13,511:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 09:35:13,622:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 09:35:13,706:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 09:35:13,707:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 09:35:13,712:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-24 09:35:13,713:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-24 09:35:13,725:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 09:35:13,734:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 09:35:13,841:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 09:35:13,924:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 09:35:13,926:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 09:35:13,932:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-24 09:35:13,940:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 09:35:13,950:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 09:35:14,065:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 09:35:14,146:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 09:35:14,147:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 09:35:14,152:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-24 09:35:14,153:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-24 09:35:14,169:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 09:35:14,288:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 09:35:14,369:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 09:35:14,370:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 09:35:14,375:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-24 09:35:14,391:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 09:35:14,513:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 09:35:14,590:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 09:35:14,591:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 09:35:14,597:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-24 09:35:14,598:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-24 09:35:14,721:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 09:35:14,797:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 09:35:14,798:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 09:35:14,802:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-24 09:35:14,920:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 09:35:14,995:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 09:35:14,996:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 09:35:15,000:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-24 09:35:15,002:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-24 09:35:15,129:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 09:35:15,204:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 09:35:15,209:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-24 09:35:15,331:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 09:35:15,406:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 09:35:15,411:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-24 09:35:15,412:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-24 09:35:15,603:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 09:35:15,608:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-24 09:35:15,796:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 09:35:15,886:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-24 09:35:15,906:INFO:Preparing preprocessing pipeline...
2023-04-24 09:35:15,906:INFO:Set up simple imputation.
2023-04-24 09:35:15,909:INFO:Set up column name cleaning.
2023-04-24 09:35:16,055:INFO:Finished creating preprocessing pipeline.
2023-04-24 09:35:16,103:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['LotFrontage', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'MasVnrArea', 'BsmtFinSF1',
                                             'BsmtFinSF2', 'BsmtUnfSF',
                                             'TotalBsmtSF', '1stFlrSF',
                                             '2ndFlrSF', 'LowQualFinSF',
                                             'GrLivArea', 'BsmtFullBath',
                                             'Bsmt...
                                             'KitchenAbvGr', 'TotRmsAbvGrd',
                                             'Fireplaces', 'GarageYrBlt',
                                             'GarageCars', 'GarageArea',
                                             'WoodDeckSF', 'OpenPorchSF',
                                             'EnclosedPorch', '3SsnPorch', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-24 09:35:16,103:INFO:Creating final display dataframe.
2023-04-24 09:35:16,473:INFO:Setup _display_container:                     Description             Value
0                    Session id              5376
1                        Target         SalePrice
2                   Target type        Regression
3           Original data shape       (1460, 318)
4        Transformed data shape       (1460, 318)
5   Transformed train set shape       (1021, 318)
6    Transformed test set shape        (439, 318)
7              Numeric features               317
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              7531
2023-04-24 09:35:16,746:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 09:35:16,750:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-24 09:35:16,934:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-24 09:35:16,938:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-24 09:35:16,939:INFO:setup() successfully completed in 6.92s...............
2023-04-24 09:35:16,951:INFO:Initializing compare_models()
2023-04-24 09:35:16,951:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001769FC9A2B0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001769FC9A2B0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-24 09:35:16,951:INFO:Checking exceptions
2023-04-24 09:35:16,963:INFO:Preparing display monitor
2023-04-24 09:35:17,062:INFO:Initializing Linear Regression
2023-04-24 09:35:17,062:INFO:Total runtime is 0.0 minutes
2023-04-24 09:35:17,078:INFO:SubProcess create_model() called ==================================
2023-04-24 09:35:17,079:INFO:Initializing create_model()
2023-04-24 09:35:17,079:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001769FC9A2B0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001769D24BB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 09:35:17,080:INFO:Checking exceptions
2023-04-24 09:35:17,080:INFO:Importing libraries
2023-04-24 09:35:17,080:INFO:Copying training dataset
2023-04-24 09:35:17,109:INFO:Defining folds
2023-04-24 09:35:17,109:INFO:Declaring metric variables
2023-04-24 09:35:17,118:INFO:Importing untrained model
2023-04-24 09:35:17,129:INFO:Linear Regression Imported successfully
2023-04-24 09:35:17,145:INFO:Starting cross validation
2023-04-24 09:35:17,310:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 09:35:37,384:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:35:37,421:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:35:37,425:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:35:38,675:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:35:40,221:INFO:Calculating mean and std
2023-04-24 09:35:40,225:INFO:Creating metrics dataframe
2023-04-24 09:35:40,476:INFO:Uploading results into container
2023-04-24 09:35:40,477:INFO:Uploading model into container now
2023-04-24 09:35:40,478:INFO:_master_model_container: 1
2023-04-24 09:35:40,479:INFO:_display_container: 2
2023-04-24 09:35:40,479:INFO:LinearRegression(n_jobs=-1)
2023-04-24 09:35:40,481:INFO:create_model() successfully completed......................................
2023-04-24 09:35:40,625:INFO:SubProcess create_model() end ==================================
2023-04-24 09:35:40,625:INFO:Creating metrics dataframe
2023-04-24 09:35:40,664:INFO:Initializing Lasso Regression
2023-04-24 09:35:40,664:INFO:Total runtime is 0.3933544119199117 minutes
2023-04-24 09:35:40,673:INFO:SubProcess create_model() called ==================================
2023-04-24 09:35:40,674:INFO:Initializing create_model()
2023-04-24 09:35:40,675:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001769FC9A2B0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001769D24BB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 09:35:40,675:INFO:Checking exceptions
2023-04-24 09:35:40,675:INFO:Importing libraries
2023-04-24 09:35:40,676:INFO:Copying training dataset
2023-04-24 09:35:40,724:INFO:Defining folds
2023-04-24 09:35:40,725:INFO:Declaring metric variables
2023-04-24 09:35:40,735:INFO:Importing untrained model
2023-04-24 09:35:40,768:INFO:Lasso Regression Imported successfully
2023-04-24 09:35:40,786:INFO:Starting cross validation
2023-04-24 09:35:40,794:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 09:35:42,470:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:35:43,382:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:35:43,830:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:35:44,958:INFO:Calculating mean and std
2023-04-24 09:35:44,960:INFO:Creating metrics dataframe
2023-04-24 09:35:45,264:INFO:Uploading results into container
2023-04-24 09:35:45,265:INFO:Uploading model into container now
2023-04-24 09:35:45,266:INFO:_master_model_container: 2
2023-04-24 09:35:45,266:INFO:_display_container: 2
2023-04-24 09:35:45,267:INFO:Lasso(random_state=5376)
2023-04-24 09:35:45,267:INFO:create_model() successfully completed......................................
2023-04-24 09:35:45,397:INFO:SubProcess create_model() end ==================================
2023-04-24 09:35:45,398:INFO:Creating metrics dataframe
2023-04-24 09:35:45,425:INFO:Initializing Ridge Regression
2023-04-24 09:35:45,425:INFO:Total runtime is 0.4727087259292603 minutes
2023-04-24 09:35:45,444:INFO:SubProcess create_model() called ==================================
2023-04-24 09:35:45,445:INFO:Initializing create_model()
2023-04-24 09:35:45,445:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001769FC9A2B0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001769D24BB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 09:35:45,446:INFO:Checking exceptions
2023-04-24 09:35:45,447:INFO:Importing libraries
2023-04-24 09:35:45,447:INFO:Copying training dataset
2023-04-24 09:35:45,498:INFO:Defining folds
2023-04-24 09:35:45,499:INFO:Declaring metric variables
2023-04-24 09:35:45,514:INFO:Importing untrained model
2023-04-24 09:35:45,523:INFO:Ridge Regression Imported successfully
2023-04-24 09:35:45,544:INFO:Starting cross validation
2023-04-24 09:35:45,550:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 09:35:47,272:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:35:47,292:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:35:49,150:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:35:49,308:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:35:49,591:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:35:50,539:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:35:51,600:INFO:Calculating mean and std
2023-04-24 09:35:51,603:INFO:Creating metrics dataframe
2023-04-24 09:35:51,833:INFO:Uploading results into container
2023-04-24 09:35:51,833:INFO:Uploading model into container now
2023-04-24 09:35:51,834:INFO:_master_model_container: 3
2023-04-24 09:35:51,836:INFO:_display_container: 2
2023-04-24 09:35:51,836:INFO:Ridge(random_state=5376)
2023-04-24 09:35:51,837:INFO:create_model() successfully completed......................................
2023-04-24 09:35:51,944:INFO:SubProcess create_model() end ==================================
2023-04-24 09:35:51,944:INFO:Creating metrics dataframe
2023-04-24 09:35:51,964:INFO:Initializing Elastic Net
2023-04-24 09:35:51,964:INFO:Total runtime is 0.581699788570404 minutes
2023-04-24 09:35:52,009:INFO:SubProcess create_model() called ==================================
2023-04-24 09:35:52,009:INFO:Initializing create_model()
2023-04-24 09:35:52,010:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001769FC9A2B0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001769D24BB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 09:35:52,010:INFO:Checking exceptions
2023-04-24 09:35:52,010:INFO:Importing libraries
2023-04-24 09:35:52,010:INFO:Copying training dataset
2023-04-24 09:35:52,077:INFO:Defining folds
2023-04-24 09:35:52,078:INFO:Declaring metric variables
2023-04-24 09:35:52,104:INFO:Importing untrained model
2023-04-24 09:35:52,129:INFO:Elastic Net Imported successfully
2023-04-24 09:35:52,196:INFO:Starting cross validation
2023-04-24 09:35:52,209:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 09:35:53,494:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:35:53,500:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:35:55,204:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:35:55,224:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:35:55,275:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:35:55,281:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:35:56,899:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:35:58,377:INFO:Calculating mean and std
2023-04-24 09:35:58,379:INFO:Creating metrics dataframe
2023-04-24 09:35:58,721:INFO:Uploading results into container
2023-04-24 09:35:58,723:INFO:Uploading model into container now
2023-04-24 09:35:58,724:INFO:_master_model_container: 4
2023-04-24 09:35:58,725:INFO:_display_container: 2
2023-04-24 09:35:58,726:INFO:ElasticNet(random_state=5376)
2023-04-24 09:35:58,726:INFO:create_model() successfully completed......................................
2023-04-24 09:35:58,913:INFO:SubProcess create_model() end ==================================
2023-04-24 09:35:58,914:INFO:Creating metrics dataframe
2023-04-24 09:35:58,950:INFO:Initializing Least Angle Regression
2023-04-24 09:35:58,950:INFO:Total runtime is 0.6981326858202617 minutes
2023-04-24 09:35:58,991:INFO:SubProcess create_model() called ==================================
2023-04-24 09:35:58,992:INFO:Initializing create_model()
2023-04-24 09:35:58,992:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001769FC9A2B0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001769D24BB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 09:35:58,993:INFO:Checking exceptions
2023-04-24 09:35:58,993:INFO:Importing libraries
2023-04-24 09:35:58,994:INFO:Copying training dataset
2023-04-24 09:35:59,062:INFO:Defining folds
2023-04-24 09:35:59,063:INFO:Declaring metric variables
2023-04-24 09:35:59,074:INFO:Importing untrained model
2023-04-24 09:35:59,086:INFO:Least Angle Regression Imported successfully
2023-04-24 09:35:59,142:INFO:Starting cross validation
2023-04-24 09:35:59,151:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 09:35:59,628:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 09:35:59,629:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 09:35:59,634:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 09:35:59,661:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 09:35:59,876:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.416e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 09:35:59,880:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=9.684e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 09:35:59,929:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=3.912e-04, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 09:35:59,943:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=2.432e-04, with an active set of 66 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 09:35:59,995:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 93 iterations, i.e. alpha=1.502e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 09:36:00,030:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=1.001e-04, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 09:36:00,074:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=9.244e-05, with an active set of 137 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 09:36:00,328:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 309 iterations, i.e. alpha=2.426e+03, with an active set of 225 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 09:36:00,415:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:776: RuntimeWarning: overflow encountered in multiply
  coef[active] = prev_coef[active] + gamma_ * least_squares

2023-04-24 09:36:00,416:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:776: RuntimeWarning: overflow encountered in add
  coef[active] = prev_coef[active] + gamma_ * least_squares

2023-04-24 09:36:00,418:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:739: RuntimeWarning: overflow encountered in true_divide
  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny32))

2023-04-24 09:36:00,419:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:735: RuntimeWarning: overflow encountered in true_divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-04-24 09:36:00,426:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:744: RuntimeWarning: overflow encountered in true_divide
  z = -coef[active] / (least_squares + tiny32)

2023-04-24 09:36:00,470:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:776: RuntimeWarning: invalid value encountered in add
  coef[active] = prev_coef[active] + gamma_ * least_squares

2023-04-24 09:36:01,248:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:36:01,255:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:36:01,256:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:36:01,470:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:36:01,848:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\utils\extmath.py:153: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b

2023-04-24 09:36:01,889:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "E:\python\Anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 761, in _score
    scores = scorer(estimator, X_test, y_test)
  File "E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 103, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 264, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py", line 191, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py", line 96, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "E:\python\Anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "E:\python\Anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float32').

  warnings.warn(

2023-04-24 09:36:02,361:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:36:02,403:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:36:02,412:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:36:02,427:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-04-24 09:36:02,428:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-04-24 09:36:02,428:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-04-24 09:36:02,429:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:805: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-04-24 09:36:02,460:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:805: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-04-24 09:36:02,469:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-04-24 09:36:02,471:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-04-24 09:36:02,472:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:805: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-04-24 09:36:03,121:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 09:36:03,195:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.283e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 09:36:03,203:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=8.694e-04, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 09:36:03,273:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=3.645e-04, with an active set of 51 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 09:36:03,512:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 09:36:03,539:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 09:36:03,570:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.250e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 09:36:03,603:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=4.665e-04, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 09:36:03,615:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=2.599e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 09:36:03,680:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=2.809e-04, with an active set of 97 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 09:36:03,690:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:744: RuntimeWarning: overflow encountered in true_divide
  z = -coef[active] / (least_squares + tiny32)

2023-04-24 09:36:03,727:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 09:36:03,768:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=9.276e-04, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 09:36:03,773:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=8.111e-04, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 09:36:03,810:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 196 iterations, i.e. alpha=3.338e-04, with an active set of 167 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 09:36:03,815:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=6.077e-04, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 09:36:03,827:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=3.631e-04, with an active set of 48 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 09:36:03,857:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=1.836e-04, with an active set of 80 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 09:36:03,886:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=1.228e-04, with an active set of 107 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 09:36:03,928:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:735: RuntimeWarning: overflow encountered in true_divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-04-24 09:36:03,929:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:739: RuntimeWarning: overflow encountered in true_divide
  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny32))

2023-04-24 09:36:04,048:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 326 iterations, i.e. alpha=4.536e-03, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 09:36:04,488:WARNING:E:\python\Anaconda3\lib\site-packages\numpy\core\fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2023-04-24 09:36:04,489:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:735: RuntimeWarning: overflow encountered in true_divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-04-24 09:36:04,489:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:739: RuntimeWarning: overflow encountered in true_divide
  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny32))

2023-04-24 09:36:04,489:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:740: RuntimeWarning: divide by zero encountered in true_divide
  gamma_ = min(g1, g2, C / AA)

2023-04-24 09:36:04,490:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:744: RuntimeWarning: overflow encountered in true_divide
  z = -coef[active] / (least_squares + tiny32)

2023-04-24 09:36:04,592:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:36:04,906:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:36:04,909:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:36:05,258:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-04-24 09:36:05,258:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-04-24 09:36:05,262:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-04-24 09:36:05,263:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-04-24 09:36:05,264:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:805: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-04-24 09:36:05,259:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:805: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-04-24 09:36:05,611:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:36:05,988:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:36:05,997:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\utils\extmath.py:153: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b

2023-04-24 09:36:05,999:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "E:\python\Anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 761, in _score
    scores = scorer(estimator, X_test, y_test)
  File "E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 103, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 264, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py", line 191, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py", line 96, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "E:\python\Anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "E:\python\Anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float32').

  warnings.warn(

2023-04-24 09:36:06,202:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 09:36:06,241:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.020e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 09:36:06,262:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=4.258e-04, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 09:36:06,302:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 09:36:06,342:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=1.176e-04, with an active set of 113 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 09:36:06,466:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=1.475e-04, with an active set of 110 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 09:36:06,734:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:36:07,430:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:36:07,657:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-04-24 09:36:07,658:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-04-24 09:36:07,659:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:805: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-04-24 09:36:07,787:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-04-24 09:36:07,788:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-04-24 09:36:07,790:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\metrics\_regression.py:805: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-04-24 09:36:08,104:INFO:Calculating mean and std
2023-04-24 09:36:08,142:WARNING:E:\python\Anaconda3\lib\site-packages\numpy\core\_methods.py:230: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)

2023-04-24 09:36:08,146:INFO:Creating metrics dataframe
2023-04-24 09:36:08,488:INFO:Uploading results into container
2023-04-24 09:36:08,489:INFO:Uploading model into container now
2023-04-24 09:36:08,490:INFO:_master_model_container: 5
2023-04-24 09:36:08,490:INFO:_display_container: 2
2023-04-24 09:36:08,491:INFO:Lars(random_state=5376)
2023-04-24 09:36:08,492:INFO:create_model() successfully completed......................................
2023-04-24 09:36:08,621:INFO:SubProcess create_model() end ==================================
2023-04-24 09:36:08,621:INFO:Creating metrics dataframe
2023-04-24 09:36:08,639:INFO:Initializing Lasso Least Angle Regression
2023-04-24 09:36:08,640:INFO:Total runtime is 0.8596216082572937 minutes
2023-04-24 09:36:08,651:INFO:SubProcess create_model() called ==================================
2023-04-24 09:36:08,651:INFO:Initializing create_model()
2023-04-24 09:36:08,652:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001769FC9A2B0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001769D24BB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 09:36:08,652:INFO:Checking exceptions
2023-04-24 09:36:08,652:INFO:Importing libraries
2023-04-24 09:36:08,653:INFO:Copying training dataset
2023-04-24 09:36:08,688:INFO:Defining folds
2023-04-24 09:36:08,689:INFO:Declaring metric variables
2023-04-24 09:36:08,702:INFO:Importing untrained model
2023-04-24 09:36:08,708:INFO:Lasso Least Angle Regression Imported successfully
2023-04-24 09:36:08,730:INFO:Starting cross validation
2023-04-24 09:36:08,741:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 09:36:09,098:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 09:36:09,191:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 09:36:09,239:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 09:36:09,242:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 09:36:09,972:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:36:10,113:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:36:10,140:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:36:10,646:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:36:11,358:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 09:36:11,473:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 09:36:11,687:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 09:36:12,245:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 09:36:12,568:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:36:12,770:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:36:12,882:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:36:13,329:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:36:14,088:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 09:36:14,166:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 09:36:14,953:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:36:15,044:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:36:17,168:INFO:Calculating mean and std
2023-04-24 09:36:17,171:INFO:Creating metrics dataframe
2023-04-24 09:36:17,803:INFO:Uploading results into container
2023-04-24 09:36:17,806:INFO:Uploading model into container now
2023-04-24 09:36:17,808:INFO:_master_model_container: 6
2023-04-24 09:36:17,808:INFO:_display_container: 2
2023-04-24 09:36:17,809:INFO:LassoLars(random_state=5376)
2023-04-24 09:36:17,809:INFO:create_model() successfully completed......................................
2023-04-24 09:36:17,971:INFO:SubProcess create_model() end ==================================
2023-04-24 09:36:17,972:INFO:Creating metrics dataframe
2023-04-24 09:36:18,005:INFO:Initializing Orthogonal Matching Pursuit
2023-04-24 09:36:18,006:INFO:Total runtime is 1.015727444489797 minutes
2023-04-24 09:36:18,018:INFO:SubProcess create_model() called ==================================
2023-04-24 09:36:18,019:INFO:Initializing create_model()
2023-04-24 09:36:18,020:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001769FC9A2B0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001769D24BB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 09:36:18,020:INFO:Checking exceptions
2023-04-24 09:36:18,020:INFO:Importing libraries
2023-04-24 09:36:18,020:INFO:Copying training dataset
2023-04-24 09:36:18,057:INFO:Defining folds
2023-04-24 09:36:18,067:INFO:Declaring metric variables
2023-04-24 09:36:18,083:INFO:Importing untrained model
2023-04-24 09:36:18,094:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-24 09:36:18,122:INFO:Starting cross validation
2023-04-24 09:36:18,130:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 09:36:18,470:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 09:36:18,498:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 09:36:18,533:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 09:36:18,547:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 09:36:20,041:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:36:20,311:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 09:36:20,363:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 09:36:20,459:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 09:36:21,050:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 09:36:21,175:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:36:22,090:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 09:36:22,104:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 09:36:24,404:INFO:Calculating mean and std
2023-04-24 09:36:24,408:INFO:Creating metrics dataframe
2023-04-24 09:36:24,882:INFO:Uploading results into container
2023-04-24 09:36:24,883:INFO:Uploading model into container now
2023-04-24 09:36:24,884:INFO:_master_model_container: 7
2023-04-24 09:36:24,885:INFO:_display_container: 2
2023-04-24 09:36:24,886:INFO:OrthogonalMatchingPursuit()
2023-04-24 09:36:24,887:INFO:create_model() successfully completed......................................
2023-04-24 09:36:25,048:INFO:SubProcess create_model() end ==================================
2023-04-24 09:36:25,048:INFO:Creating metrics dataframe
2023-04-24 09:36:25,074:INFO:Initializing Bayesian Ridge
2023-04-24 09:36:25,075:INFO:Total runtime is 1.1335360924402873 minutes
2023-04-24 09:36:25,085:INFO:SubProcess create_model() called ==================================
2023-04-24 09:36:25,086:INFO:Initializing create_model()
2023-04-24 09:36:25,087:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001769FC9A2B0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001769D24BB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 09:36:25,087:INFO:Checking exceptions
2023-04-24 09:36:25,087:INFO:Importing libraries
2023-04-24 09:36:25,088:INFO:Copying training dataset
2023-04-24 09:36:25,121:INFO:Defining folds
2023-04-24 09:36:25,122:INFO:Declaring metric variables
2023-04-24 09:36:25,139:INFO:Importing untrained model
2023-04-24 09:36:25,154:INFO:Bayesian Ridge Imported successfully
2023-04-24 09:36:25,177:INFO:Starting cross validation
2023-04-24 09:36:25,186:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 09:36:28,863:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:36:31,014:INFO:Calculating mean and std
2023-04-24 09:36:31,017:INFO:Creating metrics dataframe
2023-04-24 09:36:31,387:INFO:Uploading results into container
2023-04-24 09:36:31,389:INFO:Uploading model into container now
2023-04-24 09:36:31,390:INFO:_master_model_container: 8
2023-04-24 09:36:31,390:INFO:_display_container: 2
2023-04-24 09:36:31,392:INFO:BayesianRidge()
2023-04-24 09:36:31,392:INFO:create_model() successfully completed......................................
2023-04-24 09:36:31,537:INFO:SubProcess create_model() end ==================================
2023-04-24 09:36:31,537:INFO:Creating metrics dataframe
2023-04-24 09:36:31,561:INFO:Initializing Passive Aggressive Regressor
2023-04-24 09:36:31,561:INFO:Total runtime is 1.2416406273841858 minutes
2023-04-24 09:36:31,573:INFO:SubProcess create_model() called ==================================
2023-04-24 09:36:31,574:INFO:Initializing create_model()
2023-04-24 09:36:31,574:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001769FC9A2B0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001769D24BB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 09:36:31,575:INFO:Checking exceptions
2023-04-24 09:36:31,575:INFO:Importing libraries
2023-04-24 09:36:31,576:INFO:Copying training dataset
2023-04-24 09:36:31,635:INFO:Defining folds
2023-04-24 09:36:31,635:INFO:Declaring metric variables
2023-04-24 09:36:31,656:INFO:Importing untrained model
2023-04-24 09:36:31,669:INFO:Passive Aggressive Regressor Imported successfully
2023-04-24 09:36:31,687:INFO:Starting cross validation
2023-04-24 09:36:31,699:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 09:36:33,337:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:36:33,401:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:36:33,435:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:36:34,972:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:36:35,118:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:36:37,655:INFO:Calculating mean and std
2023-04-24 09:36:37,657:INFO:Creating metrics dataframe
2023-04-24 09:36:37,969:INFO:Uploading results into container
2023-04-24 09:36:37,970:INFO:Uploading model into container now
2023-04-24 09:36:37,971:INFO:_master_model_container: 9
2023-04-24 09:36:37,972:INFO:_display_container: 2
2023-04-24 09:36:37,973:INFO:PassiveAggressiveRegressor(random_state=5376)
2023-04-24 09:36:37,973:INFO:create_model() successfully completed......................................
2023-04-24 09:36:38,113:INFO:SubProcess create_model() end ==================================
2023-04-24 09:36:38,113:INFO:Creating metrics dataframe
2023-04-24 09:36:38,132:INFO:Initializing Huber Regressor
2023-04-24 09:36:38,132:INFO:Total runtime is 1.3511667807896932 minutes
2023-04-24 09:36:38,138:INFO:SubProcess create_model() called ==================================
2023-04-24 09:36:38,139:INFO:Initializing create_model()
2023-04-24 09:36:38,139:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001769FC9A2B0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001769D24BB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 09:36:38,140:INFO:Checking exceptions
2023-04-24 09:36:38,140:INFO:Importing libraries
2023-04-24 09:36:38,141:INFO:Copying training dataset
2023-04-24 09:36:38,170:INFO:Defining folds
2023-04-24 09:36:38,170:INFO:Declaring metric variables
2023-04-24 09:36:38,182:INFO:Importing untrained model
2023-04-24 09:36:38,198:INFO:Huber Regressor Imported successfully
2023-04-24 09:36:38,218:INFO:Starting cross validation
2023-04-24 09:36:38,226:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 09:36:39,929:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 09:36:39,930:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 09:36:39,930:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 09:36:39,958:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 09:36:42,581:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 09:36:42,616:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 09:36:42,695:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 09:36:42,769:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 09:36:43,978:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:36:45,279:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 09:36:45,284:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 09:36:46,195:INFO:Calculating mean and std
2023-04-24 09:36:46,200:INFO:Creating metrics dataframe
2023-04-24 09:36:46,648:INFO:Uploading results into container
2023-04-24 09:36:46,649:INFO:Uploading model into container now
2023-04-24 09:36:46,650:INFO:_master_model_container: 10
2023-04-24 09:36:46,651:INFO:_display_container: 2
2023-04-24 09:36:46,652:INFO:HuberRegressor()
2023-04-24 09:36:46,652:INFO:create_model() successfully completed......................................
2023-04-24 09:36:46,791:INFO:SubProcess create_model() end ==================================
2023-04-24 09:36:46,792:INFO:Creating metrics dataframe
2023-04-24 09:36:46,817:INFO:Initializing K Neighbors Regressor
2023-04-24 09:36:46,818:INFO:Total runtime is 1.495919366677602 minutes
2023-04-24 09:36:46,830:INFO:SubProcess create_model() called ==================================
2023-04-24 09:36:46,831:INFO:Initializing create_model()
2023-04-24 09:36:46,831:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001769FC9A2B0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001769D24BB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 09:36:46,832:INFO:Checking exceptions
2023-04-24 09:36:46,832:INFO:Importing libraries
2023-04-24 09:36:46,832:INFO:Copying training dataset
2023-04-24 09:36:46,864:INFO:Defining folds
2023-04-24 09:36:46,867:INFO:Declaring metric variables
2023-04-24 09:36:46,880:INFO:Importing untrained model
2023-04-24 09:36:46,887:INFO:K Neighbors Regressor Imported successfully
2023-04-24 09:36:46,905:INFO:Starting cross validation
2023-04-24 09:36:46,912:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 09:36:51,287:INFO:Calculating mean and std
2023-04-24 09:36:51,290:INFO:Creating metrics dataframe
2023-04-24 09:36:51,596:INFO:Uploading results into container
2023-04-24 09:36:51,597:INFO:Uploading model into container now
2023-04-24 09:36:51,598:INFO:_master_model_container: 11
2023-04-24 09:36:51,598:INFO:_display_container: 2
2023-04-24 09:36:51,599:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-24 09:36:51,599:INFO:create_model() successfully completed......................................
2023-04-24 09:36:51,708:INFO:SubProcess create_model() end ==================================
2023-04-24 09:36:51,708:INFO:Creating metrics dataframe
2023-04-24 09:36:51,725:INFO:Initializing Decision Tree Regressor
2023-04-24 09:36:51,725:INFO:Total runtime is 1.577705732981364 minutes
2023-04-24 09:36:51,732:INFO:SubProcess create_model() called ==================================
2023-04-24 09:36:51,733:INFO:Initializing create_model()
2023-04-24 09:36:51,734:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001769FC9A2B0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001769D24BB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 09:36:51,734:INFO:Checking exceptions
2023-04-24 09:36:51,735:INFO:Importing libraries
2023-04-24 09:36:51,735:INFO:Copying training dataset
2023-04-24 09:36:51,763:INFO:Defining folds
2023-04-24 09:36:51,764:INFO:Declaring metric variables
2023-04-24 09:36:51,778:INFO:Importing untrained model
2023-04-24 09:36:51,789:INFO:Decision Tree Regressor Imported successfully
2023-04-24 09:36:51,806:INFO:Starting cross validation
2023-04-24 09:36:51,813:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 09:36:54,549:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:36:56,543:INFO:Calculating mean and std
2023-04-24 09:36:56,546:INFO:Creating metrics dataframe
2023-04-24 09:36:56,868:INFO:Uploading results into container
2023-04-24 09:36:56,869:INFO:Uploading model into container now
2023-04-24 09:36:56,870:INFO:_master_model_container: 12
2023-04-24 09:36:56,870:INFO:_display_container: 2
2023-04-24 09:36:56,872:INFO:DecisionTreeRegressor(random_state=5376)
2023-04-24 09:36:56,873:INFO:create_model() successfully completed......................................
2023-04-24 09:36:56,982:INFO:SubProcess create_model() end ==================================
2023-04-24 09:36:56,983:INFO:Creating metrics dataframe
2023-04-24 09:36:57,000:INFO:Initializing Random Forest Regressor
2023-04-24 09:36:57,000:INFO:Total runtime is 1.665621773401896 minutes
2023-04-24 09:36:57,007:INFO:SubProcess create_model() called ==================================
2023-04-24 09:36:57,007:INFO:Initializing create_model()
2023-04-24 09:36:57,008:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001769FC9A2B0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001769D24BB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 09:36:57,008:INFO:Checking exceptions
2023-04-24 09:36:57,009:INFO:Importing libraries
2023-04-24 09:36:57,009:INFO:Copying training dataset
2023-04-24 09:36:57,033:INFO:Defining folds
2023-04-24 09:36:57,033:INFO:Declaring metric variables
2023-04-24 09:36:57,045:INFO:Importing untrained model
2023-04-24 09:36:57,064:INFO:Random Forest Regressor Imported successfully
2023-04-24 09:36:57,090:INFO:Starting cross validation
2023-04-24 09:36:57,119:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 09:37:02,678:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:37:02,683:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:37:02,771:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:37:03,661:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:37:03,772:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:37:05,081:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:37:08,362:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:37:08,392:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:37:09,692:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:37:09,743:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:37:10,831:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:37:11,831:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:37:12,165:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:37:13,376:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:37:16,238:INFO:Calculating mean and std
2023-04-24 09:37:16,241:INFO:Creating metrics dataframe
2023-04-24 09:37:16,675:INFO:Uploading results into container
2023-04-24 09:37:16,676:INFO:Uploading model into container now
2023-04-24 09:37:16,677:INFO:_master_model_container: 13
2023-04-24 09:37:16,677:INFO:_display_container: 2
2023-04-24 09:37:16,678:INFO:RandomForestRegressor(n_jobs=-1, random_state=5376)
2023-04-24 09:37:16,678:INFO:create_model() successfully completed......................................
2023-04-24 09:37:16,808:INFO:SubProcess create_model() end ==================================
2023-04-24 09:37:16,808:INFO:Creating metrics dataframe
2023-04-24 09:37:16,837:INFO:Initializing Extra Trees Regressor
2023-04-24 09:37:16,837:INFO:Total runtime is 1.9962483962376911 minutes
2023-04-24 09:37:16,845:INFO:SubProcess create_model() called ==================================
2023-04-24 09:37:16,846:INFO:Initializing create_model()
2023-04-24 09:37:16,846:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001769FC9A2B0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001769D24BB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 09:37:16,847:INFO:Checking exceptions
2023-04-24 09:37:16,847:INFO:Importing libraries
2023-04-24 09:37:16,847:INFO:Copying training dataset
2023-04-24 09:37:16,874:INFO:Defining folds
2023-04-24 09:37:16,875:INFO:Declaring metric variables
2023-04-24 09:37:16,890:INFO:Importing untrained model
2023-04-24 09:37:16,905:INFO:Extra Trees Regressor Imported successfully
2023-04-24 09:37:16,922:INFO:Starting cross validation
2023-04-24 09:37:16,928:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 09:37:22,868:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:37:22,970:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:37:23,591:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:37:23,710:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:37:23,871:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:37:23,962:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:37:24,829:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:37:29,944:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:37:30,309:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:37:31,032:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:37:31,142:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:37:31,429:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:37:32,459:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:37:34,211:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:37:36,476:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:37:36,538:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:37:37,376:INFO:Calculating mean and std
2023-04-24 09:37:37,381:INFO:Creating metrics dataframe
2023-04-24 09:37:37,970:INFO:Uploading results into container
2023-04-24 09:37:37,972:INFO:Uploading model into container now
2023-04-24 09:37:37,973:INFO:_master_model_container: 14
2023-04-24 09:37:37,974:INFO:_display_container: 2
2023-04-24 09:37:37,975:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=5376)
2023-04-24 09:37:37,976:INFO:create_model() successfully completed......................................
2023-04-24 09:37:38,204:INFO:SubProcess create_model() end ==================================
2023-04-24 09:37:38,204:INFO:Creating metrics dataframe
2023-04-24 09:37:38,265:INFO:Initializing AdaBoost Regressor
2023-04-24 09:37:38,266:INFO:Total runtime is 2.3533929944038388 minutes
2023-04-24 09:37:38,301:INFO:SubProcess create_model() called ==================================
2023-04-24 09:37:38,302:INFO:Initializing create_model()
2023-04-24 09:37:38,302:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001769FC9A2B0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001769D24BB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 09:37:38,303:INFO:Checking exceptions
2023-04-24 09:37:38,303:INFO:Importing libraries
2023-04-24 09:37:38,303:INFO:Copying training dataset
2023-04-24 09:37:38,339:INFO:Defining folds
2023-04-24 09:37:38,339:INFO:Declaring metric variables
2023-04-24 09:37:38,359:INFO:Importing untrained model
2023-04-24 09:37:38,370:INFO:AdaBoost Regressor Imported successfully
2023-04-24 09:37:38,390:INFO:Starting cross validation
2023-04-24 09:37:38,397:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 09:37:44,436:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:37:46,707:INFO:Calculating mean and std
2023-04-24 09:37:46,712:INFO:Creating metrics dataframe
2023-04-24 09:37:47,225:INFO:Uploading results into container
2023-04-24 09:37:47,226:INFO:Uploading model into container now
2023-04-24 09:37:47,227:INFO:_master_model_container: 15
2023-04-24 09:37:47,227:INFO:_display_container: 2
2023-04-24 09:37:47,228:INFO:AdaBoostRegressor(random_state=5376)
2023-04-24 09:37:47,229:INFO:create_model() successfully completed......................................
2023-04-24 09:37:47,351:INFO:SubProcess create_model() end ==================================
2023-04-24 09:37:47,351:INFO:Creating metrics dataframe
2023-04-24 09:37:47,377:INFO:Initializing Gradient Boosting Regressor
2023-04-24 09:37:47,377:INFO:Total runtime is 2.5052390575408934 minutes
2023-04-24 09:37:47,388:INFO:SubProcess create_model() called ==================================
2023-04-24 09:37:47,388:INFO:Initializing create_model()
2023-04-24 09:37:47,389:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001769FC9A2B0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001769D24BB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 09:37:47,389:INFO:Checking exceptions
2023-04-24 09:37:47,390:INFO:Importing libraries
2023-04-24 09:37:47,390:INFO:Copying training dataset
2023-04-24 09:37:47,417:INFO:Defining folds
2023-04-24 09:37:47,417:INFO:Declaring metric variables
2023-04-24 09:37:47,427:INFO:Importing untrained model
2023-04-24 09:37:47,439:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 09:37:47,457:INFO:Starting cross validation
2023-04-24 09:37:47,463:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 09:37:51,502:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:37:54,581:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:37:54,649:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:37:54,766:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:37:55,902:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:37:56,121:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:37:56,137:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:37:57,446:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:38:00,469:INFO:Calculating mean and std
2023-04-24 09:38:00,473:INFO:Creating metrics dataframe
2023-04-24 09:38:01,124:INFO:Uploading results into container
2023-04-24 09:38:01,127:INFO:Uploading model into container now
2023-04-24 09:38:01,129:INFO:_master_model_container: 16
2023-04-24 09:38:01,129:INFO:_display_container: 2
2023-04-24 09:38:01,130:INFO:GradientBoostingRegressor(random_state=5376)
2023-04-24 09:38:01,130:INFO:create_model() successfully completed......................................
2023-04-24 09:38:01,273:INFO:SubProcess create_model() end ==================================
2023-04-24 09:38:01,273:INFO:Creating metrics dataframe
2023-04-24 09:38:01,307:INFO:Initializing Extreme Gradient Boosting
2023-04-24 09:38:01,307:INFO:Total runtime is 2.7374051610628762 minutes
2023-04-24 09:38:01,320:INFO:SubProcess create_model() called ==================================
2023-04-24 09:38:01,321:INFO:Initializing create_model()
2023-04-24 09:38:01,321:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001769FC9A2B0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001769D24BB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 09:38:01,322:INFO:Checking exceptions
2023-04-24 09:38:01,322:INFO:Importing libraries
2023-04-24 09:38:01,322:INFO:Copying training dataset
2023-04-24 09:38:01,349:INFO:Defining folds
2023-04-24 09:38:01,349:INFO:Declaring metric variables
2023-04-24 09:38:01,370:INFO:Importing untrained model
2023-04-24 09:38:01,380:INFO:Extreme Gradient Boosting Imported successfully
2023-04-24 09:38:01,396:INFO:Starting cross validation
2023-04-24 09:38:01,399:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 09:38:08,147:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:38:08,441:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:38:15,750:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:38:15,872:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:38:20,630:INFO:Calculating mean and std
2023-04-24 09:38:20,634:INFO:Creating metrics dataframe
2023-04-24 09:38:21,181:INFO:Uploading results into container
2023-04-24 09:38:21,182:INFO:Uploading model into container now
2023-04-24 09:38:21,184:INFO:_master_model_container: 17
2023-04-24 09:38:21,185:INFO:_display_container: 2
2023-04-24 09:38:21,187:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=5376, ...)
2023-04-24 09:38:21,188:INFO:create_model() successfully completed......................................
2023-04-24 09:38:21,310:INFO:SubProcess create_model() end ==================================
2023-04-24 09:38:21,311:INFO:Creating metrics dataframe
2023-04-24 09:38:21,332:INFO:Initializing Light Gradient Boosting Machine
2023-04-24 09:38:21,332:INFO:Total runtime is 3.071151860555013 minutes
2023-04-24 09:38:21,342:INFO:SubProcess create_model() called ==================================
2023-04-24 09:38:21,343:INFO:Initializing create_model()
2023-04-24 09:38:21,343:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001769FC9A2B0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001769D24BB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 09:38:21,344:INFO:Checking exceptions
2023-04-24 09:38:21,344:INFO:Importing libraries
2023-04-24 09:38:21,345:INFO:Copying training dataset
2023-04-24 09:38:21,367:INFO:Defining folds
2023-04-24 09:38:21,368:INFO:Declaring metric variables
2023-04-24 09:38:21,377:INFO:Importing untrained model
2023-04-24 09:38:21,385:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-24 09:38:21,403:INFO:Starting cross validation
2023-04-24 09:38:21,408:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 09:38:26,396:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:38:28,318:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:38:28,383:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:38:28,500:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:38:29,377:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:38:29,504:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:38:29,532:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:38:30,151:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:38:32,492:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:38:34,343:INFO:Calculating mean and std
2023-04-24 09:38:34,347:INFO:Creating metrics dataframe
2023-04-24 09:38:35,155:INFO:Uploading results into container
2023-04-24 09:38:35,157:INFO:Uploading model into container now
2023-04-24 09:38:35,158:INFO:_master_model_container: 18
2023-04-24 09:38:35,158:INFO:_display_container: 2
2023-04-24 09:38:35,159:INFO:LGBMRegressor(random_state=5376)
2023-04-24 09:38:35,160:INFO:create_model() successfully completed......................................
2023-04-24 09:38:35,323:INFO:SubProcess create_model() end ==================================
2023-04-24 09:38:35,324:INFO:Creating metrics dataframe
2023-04-24 09:38:35,364:INFO:Initializing CatBoost Regressor
2023-04-24 09:38:35,364:INFO:Total runtime is 3.305027667681376 minutes
2023-04-24 09:38:35,375:INFO:SubProcess create_model() called ==================================
2023-04-24 09:38:35,376:INFO:Initializing create_model()
2023-04-24 09:38:35,376:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001769FC9A2B0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001769D24BB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 09:38:35,377:INFO:Checking exceptions
2023-04-24 09:38:35,377:INFO:Importing libraries
2023-04-24 09:38:35,377:INFO:Copying training dataset
2023-04-24 09:38:35,410:INFO:Defining folds
2023-04-24 09:38:35,410:INFO:Declaring metric variables
2023-04-24 09:38:35,421:INFO:Importing untrained model
2023-04-24 09:38:35,527:INFO:CatBoost Regressor Imported successfully
2023-04-24 09:38:35,550:INFO:Starting cross validation
2023-04-24 09:38:35,561:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 09:39:13,318:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:39:13,543:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:39:13,886:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:39:14,321:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:39:14,862:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:39:15,967:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:39:51,226:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:39:51,621:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:39:53,388:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 09:40:14,079:INFO:Calculating mean and std
2023-04-24 09:40:14,085:INFO:Creating metrics dataframe
2023-04-24 09:40:14,986:INFO:Uploading results into container
2023-04-24 09:40:14,988:INFO:Uploading model into container now
2023-04-24 09:40:14,989:INFO:_master_model_container: 19
2023-04-24 09:40:14,989:INFO:_display_container: 2
2023-04-24 09:40:14,990:INFO:<catboost.core.CatBoostRegressor object at 0x00000176A2658E50>
2023-04-24 09:40:14,991:INFO:create_model() successfully completed......................................
2023-04-24 09:40:15,182:INFO:SubProcess create_model() end ==================================
2023-04-24 09:40:15,182:INFO:Creating metrics dataframe
2023-04-24 09:40:15,228:INFO:Initializing Dummy Regressor
2023-04-24 09:40:15,228:INFO:Total runtime is 4.969421994686126 minutes
2023-04-24 09:40:15,240:INFO:SubProcess create_model() called ==================================
2023-04-24 09:40:15,241:INFO:Initializing create_model()
2023-04-24 09:40:15,242:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001769FC9A2B0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001769D24BB50>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 09:40:15,242:INFO:Checking exceptions
2023-04-24 09:40:15,243:INFO:Importing libraries
2023-04-24 09:40:15,243:INFO:Copying training dataset
2023-04-24 09:40:15,283:INFO:Defining folds
2023-04-24 09:40:15,283:INFO:Declaring metric variables
2023-04-24 09:40:15,297:INFO:Importing untrained model
2023-04-24 09:40:15,313:INFO:Dummy Regressor Imported successfully
2023-04-24 09:40:15,337:INFO:Starting cross validation
2023-04-24 09:40:15,343:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 09:40:16,540:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:40:17,737:WARNING:E:\python\Anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 09:40:22,094:INFO:Calculating mean and std
2023-04-24 09:40:22,102:INFO:Creating metrics dataframe
2023-04-24 09:40:22,820:INFO:Uploading results into container
2023-04-24 09:40:22,822:INFO:Uploading model into container now
2023-04-24 09:40:22,823:INFO:_master_model_container: 20
2023-04-24 09:40:22,823:INFO:_display_container: 2
2023-04-24 09:40:22,824:INFO:DummyRegressor()
2023-04-24 09:40:22,825:INFO:create_model() successfully completed......................................
2023-04-24 09:40:22,953:INFO:SubProcess create_model() end ==================================
2023-04-24 09:40:22,953:INFO:Creating metrics dataframe
2023-04-24 09:40:23,039:INFO:Initializing create_model()
2023-04-24 09:40:23,041:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001769FC9A2B0>, estimator=<catboost.core.CatBoostRegressor object at 0x00000176A2658E50>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 09:40:23,041:INFO:Checking exceptions
2023-04-24 09:40:23,046:INFO:Importing libraries
2023-04-24 09:40:23,046:INFO:Copying training dataset
2023-04-24 09:40:23,073:INFO:Defining folds
2023-04-24 09:40:23,074:INFO:Declaring metric variables
2023-04-24 09:40:23,074:INFO:Importing untrained model
2023-04-24 09:40:23,074:INFO:Declaring custom model
2023-04-24 09:40:23,075:INFO:CatBoost Regressor Imported successfully
2023-04-24 09:40:23,086:INFO:Cross validation set to False
2023-04-24 09:40:23,086:INFO:Fitting Model
2023-04-24 09:40:33,740:INFO:<catboost.core.CatBoostRegressor object at 0x000001769FF00670>
2023-04-24 09:40:33,741:INFO:create_model() successfully completed......................................
2023-04-24 09:40:33,949:INFO:_master_model_container: 20
2023-04-24 09:40:33,949:INFO:_display_container: 2
2023-04-24 09:40:33,950:INFO:<catboost.core.CatBoostRegressor object at 0x000001769FF00670>
2023-04-24 09:40:33,950:INFO:compare_models() successfully completed......................................
2023-04-24 11:04:13,510:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 11:04:13,799:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 11:11:09,370:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_2200\3334581977.py:5: RuntimeWarning: invalid value encountered in sqrt
  result = np.exp(np.sqrt(cross_val_score(model,train_final,log_target,scoring='neg_mean_squared_error',cv=kf)))

2023-04-24 11:11:10,707:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_2200\3334581977.py:5: RuntimeWarning: invalid value encountered in sqrt
  result = np.exp(np.sqrt(cross_val_score(model,train_final,log_target,scoring='neg_mean_squared_error',cv=kf)))

2023-04-24 11:11:11,706:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 11:11:12,473:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 11:11:13,228:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 11:11:13,984:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 11:11:14,759:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 11:11:15,509:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 11:11:16,301:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 11:11:17,061:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 11:11:17,806:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 11:11:18,544:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 11:11:18,552:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_2200\3334581977.py:5: RuntimeWarning: invalid value encountered in sqrt
  result = np.exp(np.sqrt(cross_val_score(model,train_final,log_target,scoring='neg_mean_squared_error',cv=kf)))

2023-04-24 11:11:18,822:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_2200\3334581977.py:5: RuntimeWarning: invalid value encountered in sqrt
  result = np.exp(np.sqrt(cross_val_score(model,train_final,log_target,scoring='neg_mean_squared_error',cv=kf)))

2023-04-24 11:11:18,826:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 11:11:18,858:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 11:11:18,895:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 11:11:18,931:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 11:11:18,964:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 11:11:18,997:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 11:11:19,035:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 11:11:19,070:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 11:11:19,104:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 11:11:19,139:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 11:11:19,171:WARNING:C:\Users\Administrator\AppData\Local\Temp\ipykernel_2200\3334581977.py:5: RuntimeWarning: invalid value encountered in sqrt
  result = np.exp(np.sqrt(cross_val_score(model,train_final,log_target,scoring='neg_mean_squared_error',cv=kf)))

2023-04-24 11:15:54,213:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 11:15:55,132:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 11:15:56,058:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 11:15:56,971:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 11:15:58,039:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 11:15:58,936:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 11:15:59,790:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 11:16:00,740:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 11:16:01,581:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 11:16:02,360:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-24 11:16:02,632:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 11:16:02,668:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 11:16:02,702:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 11:16:02,736:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 11:16:02,771:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 11:16:02,818:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 11:16:02,847:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 11:16:02,880:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 11:16:02,913:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 11:16:02,947:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 11:16:29,545:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 11:18:35,306:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 11:18:35,351:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 11:18:35,393:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 11:18:35,437:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 11:18:35,484:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 11:18:35,532:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 11:18:35,577:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 11:18:35,620:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 11:18:35,663:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 11:18:35,725:WARNING:E:\python\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

